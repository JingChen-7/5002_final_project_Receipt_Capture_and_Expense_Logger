{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "227dd59d-24fd-4767-8138-74ae1c2ddb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n",
      "æ‰€æœ‰åº“å¯¼å…¥æˆåŠŸï¼\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from paddleocr import PaddleOCR\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore') #Ignore all Python warnings / å¿½ç•¥æ‰€æœ‰Pythonè­¦å‘Š\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(\"æ‰€æœ‰åº“å¯¼å…¥æˆåŠŸï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b93b64-7e85-4786-87fa-ae6c00d98c72",
   "metadata": {},
   "source": [
    "# PART 1: Image Preprocessing Functions\n",
    "# ç¬¬ä¸€éƒ¨åˆ†ï¼šå›¾åƒé¢„å¤„ç†å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d5214d6-f6cc-48f9-aa96-3c108f9d4705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image from file / ä»æ–‡ä»¶åŠ è½½å›¾åƒ\n",
    "def load_image(image_path):\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"âŒ Error: File not found - {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(\"âŒ Error: Cannot read image\")\n",
    "        return None\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Complete image preprocessing pipeline / å®Œæ•´çš„å›¾åƒé¢„å¤„ç†æµç¨‹\n",
    "def preprocess_image(image_path):\n",
    "\n",
    "    # Load image / åŠ è½½å›¾åƒ\n",
    "    original = load_image(image_path)\n",
    "    if original is None:\n",
    "        return None\n",
    "    \n",
    "    # Convert to grayscale / è½¬æ¢ä¸ºç°åº¦å›¾\n",
    "    gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Remove noise / å»é™¤å™ªå£°\n",
    "    denoised = cv2.fastNlMeansDenoising(gray, None, 10, 7, 21)\n",
    "    \n",
    "    # Apply threshold / åº”ç”¨é˜ˆå€¼\n",
    "    threshold = cv2.adaptiveThreshold(\n",
    "        denoised, 255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY, 11, 2\n",
    "    )\n",
    "    \n",
    "    return threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f21c7de-6502-4510-857b-fa9148a1c226",
   "metadata": {},
   "source": [
    "# PART 2: OCR Recognition Functions\n",
    "# ç¬¬äºŒéƒ¨åˆ†ï¼šOCRè¯†åˆ«å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c010d951-585d-4a26-9b34-3c32c48c5b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize PaddleOCR engine / åˆå§‹åŒ–PaddleOCRå¼•æ“\n",
    "def initialize_ocr():\n",
    "    ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
    "    return ocr\n",
    "\n",
    "#Perform OCR on image / å¯¹å›¾åƒæ‰§è¡ŒOCR\n",
    "def perform_ocr(ocr, image_path):\n",
    "    #print(\"Get all text from OCR... / æ‰§è¡ŒPCRè·å–åŸå§‹æ•°æ®\")\n",
    "    result = ocr.ocr(image_path)\n",
    "    \n",
    "    if result is None or len(result) == 0:\n",
    "        print(\"âŒ OCR returned no results!\")\n",
    "        return []\n",
    "    \n",
    "    #print(\"=\"*70 + \"\\n\")\n",
    "    #æ‰“å°ocrè¿”å›çš„åˆå§‹ç»“æœ\n",
    "    #print(result)\n",
    "    #print(\"=\"*70 + \"\\n\")\n",
    "    return result[0] if len(result) > 0 else []\n",
    "\n",
    "#Organize OCR results / æ•´ç†OCRç»“æœ\n",
    "def organize_ocr_results(ocr_result):\n",
    "    #organized_list = []\n",
    "    df_ocr_result = pd.DataFrame(columns=[\"text\",\"confidence\",\"left_top_x\",\"left_top_y\",\"right_top_x\",\"right_top_y\",\"left_bottom_x\",\"left_bottom_y\",\"right_bottom_x\",\"right_bottom_y\",\"center_x\",\"center_y\"])\n",
    "    \n",
    "    print(\"ORGANIZING OCR DATA / æ•´ç†OCRæ•°æ®:\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    texts = ocr_result.get('rec_texts', [])\n",
    "    scores = ocr_result.get('rec_scores', [1.0] * len(texts))\n",
    "    polys = ocr_result.get('rec_polys', [])\n",
    "\n",
    "    \n",
    "    for idx, text in enumerate(texts):\n",
    "        confidence = scores[idx] if idx < len(scores) else 1.0   #å½“scoreså’Œtexté•¿åº¦ä¸ä¸€è‡´ç”¨1.0è¡¥å…¨\n",
    "        \n",
    "        # Get coordinates / è·å–å¤šåæ ‡\n",
    "        if idx < len(polys) and len(polys[idx]) >= 4:\n",
    "            poly = polys[idx]\n",
    "            \n",
    "            # Calculate center point / è®¡ç®—ä¸­å¿ƒç‚¹\n",
    "            center_x = (poly[0][0] + poly[2][0]) / 2\n",
    "            center_y = (poly[0][1] + poly[2][1]) / 2\n",
    "            \n",
    "            # Format: (x1,y1)(x2,y2)(x3,y3)(x4,y4)(center_x,center_y)\n",
    "            pos_str = f\"({poly[0][0]:.0f},{poly[0][1]:.0f})({poly[1][0]:.0f},{poly[1][1]:.0f})({poly[2][0]:.0f},{poly[2][1]:.0f})({poly[3][0]:.0f},{poly[3][1]:.0f})({center_x:.0f},{center_y:.0f})\"\n",
    "            \n",
    "        else:\n",
    "            pos_str = \"(0,0)(0,0)(0,0)(0,0)(0,0)\"\n",
    "            center_x = 0\n",
    "            center_y = 0\n",
    "            y_position = idx * 10\n",
    "            x_position = 0\n",
    "        \n",
    "        # Print in compact format / ä»¥ç´§å‡‘æ ¼å¼æ‰“å°\n",
    "        #print(f\"{idx+1}. Text: '{text}' | Confidence: {confidence:.2f} | Position: {pos_str}\")\n",
    "\n",
    "        # Save text into dataframe / æŠŠç»“æœä¿å­˜åˆ°dataframe\n",
    "        df_ocr_result.loc[len(df_ocr_result.index)] = [str(text),float(confidence),poly[0][0],poly[0][1],poly[1][0],poly[1][1],poly[2][0],poly[2][1],poly[3][0],poly[3][1],center_x,center_y]\n",
    "        \n",
    "    #print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "    #organized_list.sort(key=lambda x: x['left_top_p'][1])\n",
    "    #print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "    return df_ocr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a309cce1-f9e1-41ca-8205-d9e5ee42e3bf",
   "metadata": {},
   "source": [
    "# PART 3: Information Extraction Functions\n",
    "# ç¬¬ä¸‰éƒ¨åˆ†ï¼šä¿¡æ¯æå–å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d378c177-8ce3-4c07-993c-26cf0e69f6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These functions must be called in order / è¿™éƒ¨åˆ†çš„å‡½æ•°å¿…é¡»æŒ‰é¡ºåºè°ƒç”¨\n",
    "\n",
    "#Extract date from text / ä»æ–‡æœ¬ä¸­æå–æ—¥æœŸ\n",
    "def extract_date(text):\n",
    "    patterns = [\n",
    "        r'\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}',        # 25/12/2018 or 12-25-18\n",
    "        r'\\d{4}[-/]\\d{1,2}[-/]\\d{1,2}',          # 2018/12/25\n",
    "        r'\\d{1,2}\\.\\d{1,2}\\.\\d{2,4}',            # 25.12.2018\n",
    "        r'\\d{1,2}\\s+\\w+\\s+\\d{2,4}',              # 25 Dec 2018\n",
    "        r'\\w+\\s+\\d{1,2},?\\s+\\d{2,4}',            # Dec 25, 2018\n",
    "        r'\\d{1,2}(st|nd|rd|th)?\\s+\\w+\\s+\\d{4}',  # 25th December 2018\n",
    "    ]\n",
    " \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            found_date = match.group()\n",
    "            #print(f\"âœ… Found date: '{found_date}' in text: '{text}'\")\n",
    "            #print(\"=\"*70 + \"\\n\")\n",
    "            return found_date\n",
    "    return 0\n",
    "\n",
    "#====================================================================================================\n",
    "# Classify text type / åˆ†ç±»æ–‡å­—ç±»å‹\n",
    "def classify_text_type(text):\n",
    "    \"\"\"\n",
    "    Classify text type / åˆ†ç±»æ–‡å­—ç±»å‹\n",
    "    \n",
    "    Returns:\n",
    "    - 'price' : Price (two decimal places) / ä»·æ ¼ï¼ˆä¸¤ä½å°æ•°ï¼‰\n",
    "    - 'code' : Code (long digit string or alphanumeric) / ç¼–ç ï¼ˆé•¿æ•°å­—ä¸²æˆ–å­—æ¯æ•°å­—æ··åˆï¼‰\n",
    "    - 'header' : Header keyword (PRICE, QTY, AMOUNT, etc.) / è¡¨å¤´å…³é”®å­—ï¼ˆPRICE, QTY, AMOUNT ç­‰ï¼‰\n",
    "    - 'payment' : Payment keyword (TOTAL, CASH, CHANGE, etc.) / ç»“è´¦å…³é”®å­—ï¼ˆTOTAL, CASH, CHANGE ç­‰ï¼‰\n",
    "    - 'text' : Regular text / æ™®é€šæ–‡å­—\n",
    "    \"\"\"  \n",
    "    \n",
    "    text_clean = text.strip()\n",
    "    text_lower = text_clean.lower()\n",
    "\n",
    "\n",
    "    # 1. Check for date type / æ£€æŸ¥æ˜¯å¦æ˜¯æ—¥æœŸ\n",
    "    if extract_date(text) != 0:\n",
    "        return 'date'\n",
    "    \n",
    "    \n",
    "    # 2. Check for header keywords / æ£€æŸ¥è¡¨å¤´å…³é”®å­—\n",
    "    header_keywords = ['price', 'amount', 'qty', 'quantity', 'item', \n",
    "                      'description', 'product', 'code', 'desc']\n",
    "    \n",
    "    if any(kw == text_lower or kw in text_lower for kw in header_keywords):\n",
    "        if len(text_clean) < 20:  # Header keywords are usually short\n",
    "            return 'header'\n",
    "    \n",
    "    # 3. Check for payment keywords / æ£€æŸ¥ç»“è´¦å…³é”®å­—\n",
    "    payment_keywords = ['total', 'subtotal', 'grand total', \n",
    "                       'cash', 'payment', 'paid',\n",
    "                       'change', 'balance',\n",
    "                       'tax', 'vat', 'gst',\n",
    "                       'discount', 'promo']\n",
    "    \n",
    "    if any(kw in text_lower for kw in payment_keywords):\n",
    "        return 'payment'\n",
    "    \n",
    "    # 4. Check if it's a price (number with 2 decimals) / æ£€æŸ¥æ˜¯å¦æ˜¯ä»·æ ¼\n",
    "    # Pattern: $12.50 or 12.50 or 12.50$\n",
    "    price_pattern = r'^\\$?\\s*\\d+[.,]\\d{2}\\s*\\$?$'\n",
    "    if re.match(price_pattern, text_clean):\n",
    "        return 'price'\n",
    "    \n",
    "    # 5. Check if it is a product code / æ£€æŸ¥æ˜¯å¦æ˜¯å•†å“ç¼–ç \n",
    "    text_no_space = text_clean.replace(' ', '').replace('-', '').replace('.', '')\n",
    "    \n",
    "    if len(text_no_space) > 0:\n",
    "        # Rule 1: Pure digits with length > 3 (4 or more digits)\n",
    "        # è§„åˆ™1ï¼šçº¯æ•°å­—ä¸”é•¿åº¦å¤§äº3ï¼ˆ4ä½åŠä»¥ä¸Šï¼‰\n",
    "        if text_no_space.isdigit() and len(text_no_space) > 3:\n",
    "            return 'code'\n",
    "        \n",
    "        # Rule 2: Digit ratio > 70%\n",
    "        # è§„åˆ™2ï¼šæ•°å­—å æ¯”å¤§äº70%\n",
    "        digit_count = sum(c.isdigit() for c in text_no_space)\n",
    "        total_length = len(text_no_space)\n",
    "        digit_ratio = digit_count / total_length\n",
    "        \n",
    "        # Also require minimum length > 5 to avoid short mixed text\n",
    "        # åŒæ—¶è¦æ±‚é•¿åº¦>3ï¼Œé¿å…çŸ­æ–‡æœ¬è¢«è¯¯åˆ¤\n",
    "        if digit_ratio > 0.7 and total_length > 3:\n",
    "            return 'code'\n",
    "\n",
    "     # 6. Check for symbols / æ£€æŸ¥æ˜¯å¦æ˜¯ç¬¦å· \n",
    "    if len(text_no_space) > 0:\n",
    "        # Remove all letters and digits / ç§»é™¤æ‰€æœ‰å­—æ¯å’Œæ•°å­—\n",
    "        text_no_alnum = re.sub(r'[a-zA-Z0-9]', '', text_no_space)\n",
    "        \n",
    "        # Calculate symbol ratio / è®¡ç®—ç¬¦å·å æ¯”\n",
    "        symbol_ratio = len(text_no_alnum) / len(text_no_space)\n",
    "        \n",
    "        # If 80% or more are symbols, mark as invalid\n",
    "        # å¦‚æœ80%ä»¥ä¸Šéƒ½æ˜¯ç¬¦å·ï¼Œæ ‡è®°ä¸ºinvalid\n",
    "        if symbol_ratio >= 0.8:\n",
    "            return 'invalid'\n",
    "\n",
    "        if len(text_no_space) < 4:\n",
    "            return 'invalid'\n",
    "\n",
    "    \n",
    "    # 7. Otherwise it's text / å…¶ä»–æƒ…å†µæ˜¯æ™®é€šæ–‡å­—\n",
    "    return 'text'\n",
    "\n",
    "#====================================================================================================\n",
    "# Add row number column / å¢åŠ è¡Œå·åˆ—\n",
    "def mark_row_number(df):\n",
    "    # Add row_No column / æ·»åŠ  row_No åˆ—\n",
    "    print(\"ADDING ROW NUMBER COLUMN / æ·»åŠ è¡Œå·:\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    row_no = 1  # Start from row 1 / ä»ç¬¬1è¡Œå¼€å§‹\n",
    "    df.loc[0, 'row_No'] = row_no  # First element corresponds to row 1 / ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯ç¬¬1è¡Œ\n",
    "    \n",
    "    # Iterate through each row and check if it's a new row / éå†æ¯ä¸€è¡Œï¼Œåˆ¤æ–­æ˜¯å¦ä¸ºæ–°è¡Œ\n",
    "    for i in range(1, len(df)):\n",
    "        # Current row's center_y / å½“å‰è¡Œçš„ center_y\n",
    "        current_y = df.loc[i, 'left_bottom_y']\n",
    "        \n",
    "        # Previous row's center_y / å‰ä¸€è¡Œçš„ center_y\n",
    "        previous_y = df.loc[i-1, 'left_bottom_y']\n",
    "        \n",
    "        # Calculate the difference / è®¡ç®—å·®è·\n",
    "        diff = abs(current_y - previous_y)\n",
    "        \n",
    "        # If difference < 20, consider same row; otherwise, assign a new row_No\n",
    "        # å¦‚æœå·®è·å°äº20ï¼Œè®¤ä¸ºæ˜¯åŒä¸€è¡Œï¼Œå¦åˆ™æ–°å¢ä¸€ä¸ªè¡Œå·\n",
    "        if diff < 20:\n",
    "            df.loc[i, 'row_No'] = row_no\n",
    "        else:\n",
    "            row_no += 1  # For a new row, increment row_No by 1 / æ–°çš„ä¸€è¡Œï¼Œrow_No åŠ  1\n",
    "            df.loc[i, 'row_No'] = row_no\n",
    "    \n",
    "    # Convert to integer type / è½¬æ¢ä¸ºæ•´æ•°ç±»å‹\n",
    "    df['row_No'] = df['row_No'].astype(int)\n",
    "    return df\n",
    "\n",
    "#====================================================================================================\n",
    "# Add priority column / æ·»åŠ priorityåˆ—\n",
    "def add_priority_column(df):\n",
    "    \"\"\"\n",
    "    Rule:\n",
    "    - Find first row where mark='header' â†’ row_head\n",
    "    - Find first row where text contains 'total' â†’ row_tail\n",
    "    - Rows where row_head <= row_No < row_tail â†’ mark as 1\n",
    "    - Other rows â†’ mark as 0\n",
    "    \n",
    "    è§„åˆ™ï¼š\n",
    "    - æ‰¾åˆ°markä¸º'header'çš„ç¬¬ä¸€è¡Œ â†’ row_head\n",
    "    - æ‰¾åˆ°textåŒ…å«'total'çš„ç¬¬ä¸€è¡Œ â†’ row_tail\n",
    "    - row_head <= row_No < row_tail çš„è¡Œ â†’ æ ‡è®°ä¸º1\n",
    "    - å…¶ä»–è¡Œ â†’ æ ‡è®°ä¸º0\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"ADDING PRIORITY COLUMN / æ·»åŠ æœ‰æ•ˆä¿¡æ¯æƒé‡åˆ—:\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Initialize / åˆå§‹åŒ–\n",
    "    df['priority'] = 0\n",
    "    \n",
    "    # Find row_head (first header row) / æ‰¾åˆ°row_headï¼ˆç¬¬ä¸€ä¸ªheaderè¡Œï¼‰\n",
    "    header_rows = df[df['mark'] == 'header']\n",
    "    \n",
    "    if len(header_rows) > 0:\n",
    "        row_head = header_rows['row_No'].min()\n",
    "        #print(f\"âœ… Found header at row_No: {row_head}\")\n",
    "        #print(f\"  Header texts: {list(header_rows['text'].values)}\")\n",
    "    else:\n",
    "        #print(\"âŒ No header found, using row_No 0 as row_head\")\n",
    "        row_head = 0\n",
    "    \n",
    "    # Find row_tail (first row with 'total' in text) / æ‰¾åˆ°row_tail\n",
    "    total_rows = df[df['text'].str.lower().str.contains('total', na=False)]\n",
    "    \n",
    "    if len(total_rows) > 0:\n",
    "        row_tail = total_rows['row_No'].min()\n",
    "        #print(f\"âœ… Found 'total' at row_No: {row_tail}\")\n",
    "        #print(f\"  Total text: '{total_rows.iloc[0]['text']}'\")\n",
    "    else:\n",
    "        #print(\"âŒ No 'total' found, using last row as row_tail\")\n",
    "        row_tail = df['row_No'].max() + 1\n",
    "    \n",
    "    # Mark valid rows / æ ‡è®°æœ‰æ•ˆè¡Œ\n",
    "    # Rows where row_head <= row_No < row_tail â†’ mark as 1\n",
    "    # Other rows â†’ mark as 0\n",
    "    df['priority'] = ((df['row_No'] >= row_head) & (df['row_No'] < row_tail)).astype(int)\n",
    "    \n",
    "    # # Count valid rows / ç»Ÿè®¡æœ‰æ•ˆè¡Œ\n",
    "    # valid_count = df['priority'].sum()\n",
    "    \n",
    "    # print(f\"\\nValid data range / æœ‰æ•ˆæ•°æ®èŒƒå›´:\")\n",
    "    # print(f\"  From row_No {row_head} to row_No {row_tail-1} (inclusive)\")\n",
    "    \n",
    "    # print(f\"\\nResults / ç»“æœ:\")\n",
    "    # print(f\"  Valid rows (priority=1): {valid_count}\")\n",
    "    # print(f\"  Invalid rows (priority=0): {len(df) - valid_count}\")\n",
    "    \n",
    "    # print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return df\n",
    "    \n",
    "#====================================================================================================    \n",
    "#Add column number column / å¢åŠ åˆ—å·åˆ—\n",
    "def add_column_number(df):\n",
    "    \"\"\"\n",
    "    Add col_No column based on x position clustering\n",
    "    æ ¹æ®xä½ç½®èšç±»æ·»åŠ col_Noåˆ—\n",
    "    \n",
    "    Rule: If any x coordinate (left_top_x, right_top_x, or center_x) \n",
    "          differs by <= 20, they are in the same column\n",
    "    è§„åˆ™ï¼šå¦‚æœä»»ä¸€xåæ ‡ç›¸å·®<=20ï¼Œå°±æ˜¯åŒä¸€åˆ—\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ADDING COLUMN NUMBERS / æ·»åŠ åˆ—å·:\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Initialize / åˆå§‹åŒ–\n",
    "    df['col_No'] = 0\n",
    "    \n",
    "    \n",
    "    # Sort by left_top_x (left to right), then by left_top_y (top to bottom) \n",
    "    # å…ˆæŒ‰ left_top_x æ’åºï¼ˆä»å·¦åˆ°å³ï¼‰ï¼Œå†æŒ‰ left_top_y æ’åºï¼ˆä»ä¸Šåˆ°ä¸‹ï¼‰\n",
    "    df_sorted = df.sort_values(['left_top_x', 'left_top_y']).reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    columns = []  # Store coordinates of all elements in the current column / ç”¨äºå­˜å‚¨å½“å‰åˆ—æ‰€æœ‰å…ƒç´ çš„åæ ‡\n",
    "    curr_col_No = 1\n",
    "\n",
    "    for row in df_sorted.itertuples():\n",
    "        left_top_x = row.left_top_x\n",
    "        right_top_x = row.right_top_x\n",
    "        width = right_top_x - left_top_x\n",
    "        text = row.text\n",
    "\n",
    "        for item in columns:\n",
    "            #left_top_x -> right_top_x forms a line segment / left_top_x -> right_top_x å½¢æˆä¸€æ¡çº¿æ®µ \n",
    "            #Check if the two segments intersect / åˆ¤æ–­ä¸¤è€…æ˜¯å¦äº¤é›†\n",
    "            is_intersect = item[0] < right_top_x and item[1] > left_top_x\n",
    "            \n",
    "            if is_intersect:\n",
    "                # Check if overlap ratio > 70% for either side; if so, consider as same column \n",
    "                # åˆ¤æ–­åŒæ–¹çš„äº¤é›†æ¯”ä¾‹æ˜¯å¦æœ‰ä¸€æ–¹è¶…è¿‡70%ï¼Œæœ‰åˆ™è®¤ä¸ºæ˜¯åŒä¸€åˆ—\n",
    "                intersect_len = min(item[1], right_top_x) - max(item[0], left_top_x)\n",
    "                is_intersect = intersect_len / width > 0.7 or intersect_len / (item[1] - item[0]) > 0.7\n",
    "                # print(f\"{intersect_len / width} {intersect_len / (item[1] - item[0])}\")\n",
    "\n",
    "            if not is_intersect:\n",
    "                # Switch to new column and clear / åˆ‡æ¢åˆ°æ–°åˆ—å¹¶æ¸…ç©º\n",
    "                columns.clear()\n",
    "                curr_col_No += 1\n",
    "                # print(f\"New column {curr_col_No} created\")\n",
    "                # print(f\"{left_top_x} {right_top_x} {item[0]} {item[1]} {item[2]} {row.text}\")\n",
    "                break\n",
    "\n",
    "        columns.append((left_top_x, right_top_x, row.text))\n",
    "        # Assign column number / åˆ†é…åˆ—å·\n",
    "        df_sorted.loc[row.Index, 'col_No'] = curr_col_No\n",
    "\n",
    "    \n",
    "    # Copy col_No back to original dataframe order\n",
    "    # å°†col_Noå¤åˆ¶å›åŸå§‹dataframeçš„é¡ºåº\n",
    "    # df['col_No'] = df_sorted['col_No'].values\n",
    "    df = df.drop(columns=['col_No'])  # drop original\n",
    "    df = df.merge(\n",
    "        df_sorted[['left_top_x', 'left_top_y', 'col_No']],\n",
    "        on=['left_top_x', 'left_top_y'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    df['col_No'] = df['col_No'].astype(int)\n",
    "    \n",
    "    #print(\"\\n\" + \"=\"*70)\n",
    "    #print(f\"è¯†åˆ«åˆ°çš„åˆ—æ•°: {curr_col_No}\")    \n",
    "    #print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return df\n",
    "    \n",
    "#====================================================================================================\n",
    "# Update category text type: mark as \"Unit\" / æ›´æ–°åˆ†ç±»æ–‡å­—ç±»å‹ï¼šæ ‡è®°ä¸ºâ€œå•ä½â€\n",
    "def mark_units(df):\n",
    "    \"\"\"\n",
    "    Mark units directly in the 'mark' column\n",
    "    ç›´æ¥åœ¨markåˆ—ä¸­æ ‡è®°å•ä½\n",
    "\n",
    "    Rules::\n",
    "    1. Directly matches common unit labels\n",
    "    2. Number followed by common unit labels\n",
    "    3. Pure number in the same column as header \"Qty\"\n",
    "\n",
    "    è§„åˆ™ï¼š\n",
    "    1. ç›´æ¥æ˜¾ç¤ºä¸ºå¸¸è§çš„å•ä½æ ‡è¯†\n",
    "    2.æ•°å­—+å¸¸è§å•ä½æ ‡è¯†\n",
    "    3.ä¸è¡¨å¤´ â€œQtyâ€ åŒåˆ—çš„çº¯æ•°å­—\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"MARKING UNITS / æ ‡è®°å•ä½:\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Common units / å¸¸è§å•ä½\n",
    "    unit_keywords = [\n",
    "        # Counting / è®¡æ•°\n",
    "        'PC', 'PCS', 'PIECE', 'PIECES', 'EA', 'EACH', 'UNIT',\n",
    "        \n",
    "        # Weight / é‡é‡\n",
    "        'KG', 'G', 'GM', 'GRAM', 'LB', 'POUND', 'OZ', 'OUNCE',\n",
    "        \n",
    "        # Volume / ä½“ç§¯\n",
    "        'L', 'ML', 'LITER', 'GAL', 'GALLON', 'FL OZ',\n",
    "        \n",
    "        # Packaging / åŒ…è£…\n",
    "        'BOX', 'BAG', 'BTL', 'BOTTLE', 'CAN', 'PKT', 'PACKET',\n",
    "        'CTN', 'CARTON', 'JAR', 'TIN', 'TUBE',\n",
    "        \n",
    "        # Other / å…¶ä»–\n",
    "        'PAIR', 'SET', 'ROLL', 'PACK', 'BUNCH', 'DOZEN', 'DZ'\n",
    "    ]\n",
    "    \n",
    "    # Find Qty column if exists / æŸ¥æ‰¾Qtyåˆ—\n",
    "    qty_headers = df[(df['mark'] == 'header') & \n",
    "                    (df['text'].str.upper().str.contains('QTY|QUANTITY', na=False))]\n",
    "    \n",
    "    qty_col = None\n",
    "    if len(qty_headers) > 0:\n",
    "        qty_col = qty_headers.iloc[0]['col_No']\n",
    "        #print(f\"Found Qty column at col_No: {qty_col}\")\n",
    "        #print(f\"æ‰¾åˆ°Qtyåˆ—ï¼Œåˆ—å·: {qty_col}\\n\")\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    # Check each row / æ£€æŸ¥æ¯ä¸€è¡Œ\n",
    "    for idx in df.index:\n",
    "        text = df.loc[idx, 'text']\n",
    "        text_upper = text.upper().strip()\n",
    "        current_mark = df.loc[idx, 'mark']\n",
    "        \n",
    "        is_unit = False\n",
    "        reason = \"\"\n",
    "        \n",
    "        # Rule 1: Keyword match / è§„åˆ™1ï¼šå…³é”®è¯åŒ¹é…\n",
    "        if text_upper in unit_keywords:\n",
    "            is_unit = True\n",
    "            reason = f\"keyword match: {text_upper}\"\n",
    "        \n",
    "        # Rule 2: Pattern match (e.g., \"1 PC\") / è§„åˆ™2ï¼šæ¨¡å¼åŒ¹é…\n",
    "        if not is_unit:\n",
    "            pattern = r'^\\d+\\.?\\d*\\s*(' + '|'.join(unit_keywords) + r')$'\n",
    "            if re.match(pattern, text_upper):\n",
    "                is_unit = True\n",
    "                reason = f\"pattern match: {text}\"\n",
    "        \n",
    "        # Rule 3: Pure number in Qty column / è§„åˆ™3ï¼šQtyåˆ—çš„çº¯æ•°å­—\n",
    "        if not is_unit and qty_col is not None:\n",
    "            current_col = df.loc[idx, 'col_No']\n",
    "            \n",
    "            if current_col == qty_col:\n",
    "                text_clean = text.replace('.', '').replace(',', '')\n",
    "                if text_clean.isdigit():\n",
    "                    try:\n",
    "                        num = float(text)\n",
    "                        if 0 < num < 1000:\n",
    "                            is_unit = True\n",
    "                            reason = f\"number in Qty column: {text}\"\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        # Update mark to 'unit' if identified / å¦‚æœè¯†åˆ«ä¸ºå•ä½ï¼Œæ›´æ–°markä¸º'unit'\n",
    "        if is_unit:\n",
    "            df.loc[idx, 'mark'] = 'unit'\n",
    "            count += 1\n",
    "            \n",
    "            row_no = df.loc[idx, 'row_No']\n",
    "            col_no = df.loc[idx, 'col_No']\n",
    "            \n",
    "            #print(f\"âœ… '{text}' (row={row_no}, col={col_no}) â†’ mark='unit'\")\n",
    "            #print(f\"    Reason: {reason}\")\n",
    "            #print(f\"    Original mark: {current_mark}\")\n",
    "    \n",
    "    #print(f\"\\nâœ… Total units marked: {count}\")\n",
    "    #print(f\"âœ… æ ‡è®°çš„å•ä½æ€»æ•°: {count}\")\n",
    "    #print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "#====================================================================================================\n",
    "# Update priority (mark as 2) / æ›´æ–°æƒé‡ï¼ˆæ ‡è®°ä¸º2ï¼‰\n",
    "def update_priority_marks(df):\n",
    "    \"\"\"\n",
    "    Update priority marks with additional rules\n",
    "    ç”¨é¢å¤–è§„åˆ™æ›´æ–°priorityæ ‡è®°\n",
    "\n",
    "    Rules:\n",
    "    1. If code and text are in same row or adjacent rows in same columnï¼Œincrease text's priority to 2\n",
    "    1: If a code and text are adjacent in the same row or column, increase text's priority to 2\n",
    "    3. If text is in same column as 'item' headerï¼Œincrease text's priority to 2\n",
    "\n",
    "    è§„åˆ™ï¼š\n",
    "    1. å¦‚æœå­˜åœ¨codeå’Œtextåœ¨åŒä¸€è¡Œæˆ–åŒä¸€åˆ—ä¸´è¿‘è¡Œï¼Œå¢åŠ textçš„ priority ä¸º2\n",
    "    2. å¦‚æœpriceå’ŒåŒ…å«amount/total/sumç­‰å…³é”®è¯çš„textåœ¨åŒä¸€åˆ—ï¼Œï¼Œå¢åŠ textçš„ priority ä¸º2\n",
    "    3. å¦‚æœtextå’Œheaderä¸º'item'åœ¨åŒä¸€åˆ—ï¼Œå¢åŠ textçš„ priority ä¸º2\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"UPDATING PRIORITY MARKS / æ›´æ–°ä¼˜å…ˆçº§æ ‡è®°:\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Keywords that indicate summary/total amounts\n",
    "    # æ ‡è¯†æ€»é¢çš„å…³é”®è¯\n",
    "    total_keywords = [\n",
    "        'amount', 'sum', 'balance', 'due', 'payable', 'net', 'gross'\n",
    "    ]\n",
    "    \n",
    "    # Rule 1: Code + Text in same/adjacent rows in same column / è§„åˆ™1ï¼šåŒä¸€è¡Œæˆ–åŒä¸€åˆ—ä¸´è¿‘è¡Œçš„codeå’Œtext \n",
    "    #print(\"\\nRule 1: Checking code + text pairs / æ£€æŸ¥codeå’Œtexté…å¯¹:\")\n",
    "    #print(\"-\"*70)\n",
    "    \n",
    "    count_rule1 = 0\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        if row['mark'] == 'text' and row['priority'] == 1:\n",
    "            text_row = row['row_No']\n",
    "            text_col = row['col_No']\n",
    "            \n",
    "            for idx2, row2 in df.iterrows():\n",
    "                if row2['mark'] == 'code':\n",
    "                    code_row = row2['row_No']\n",
    "                    code_col = row2['col_No']\n",
    "                    \n",
    "                    same_row = (text_row == code_row)\n",
    "                    same_col = (text_col == code_col)\n",
    "                    adjacent_row = abs(text_row - code_row) == 1\n",
    "                    \n",
    "                    if same_row or (same_col and adjacent_row):\n",
    "                        df.loc[idx, 'priority'] = 2\n",
    "                        count_rule1 += 1\n",
    "                        # print(f\"âœ… Text '{row['text'][:30]}' (row={text_row}, col={text_col}) â†’ priority=2\")\n",
    "                        # print(f\"    Paired with code '{row2['text']}' (row={code_row}, col={code_col})\")\n",
    "                        break\n",
    "    \n",
    "    # print(f\"\\nRule 1 applied to {count_rule1} text items\")\n",
    "    \n",
    "    # Rule 2: Price + Total keywords /è§„åˆ™2ï¼šä»·æ ¼å’Œæ€»é¢å…³é”®è¯   \n",
    "    # print(\"Rule 2: Checking price + total keyword pairs / æ£€æŸ¥priceå’Œæ€»é¢å…³é”®è¯é…å¯¹...\")\n",
    "    # print(\"-\"*70)\n",
    "    \n",
    "    count_rule2 = 0\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        if row['mark'] == 'price':\n",
    "            price_col = row['col_No']\n",
    "            price_row = row['row_No']\n",
    "            \n",
    "            for idx2, row2 in df.iterrows():\n",
    "                text_lower = row2['text'].lower()\n",
    "                \n",
    "                contains_keyword = any(kw in text_lower for kw in total_keywords)\n",
    "                \n",
    "                if contains_keyword and row2['col_No'] == price_col:\n",
    "                    matched_keyword = next((kw for kw in total_keywords if kw in text_lower), '')\n",
    "                    \n",
    "                    df.loc[idx, 'priority'] = 2\n",
    "                    count_rule2 += 1\n",
    "                    \n",
    "                    #print(f\"âœ… Price '{row['text']}' (row={price_row}, col={price_col}) â†’ priority=2\")\n",
    "                    #print(f\"    Same column as '{row2['text']}' (contains '{matched_keyword}')\")\n",
    "                    break\n",
    "    \n",
    "    #print(f\"\\nRule 2 applied to {count_rule2} price items\")\n",
    "\n",
    "    \n",
    "    # Rule 3: Text in same column as 'item' header / è§„åˆ™3ï¼štextå’Œ'item'è¡¨å¤´åœ¨åŒä¸€åˆ—\n",
    "    \n",
    "    #print(\"\\n\" + \"-\"*70)\n",
    "    #print(\"Rule 3: Checking text in 'item' column / æ£€æŸ¥itemåˆ—çš„text:\")\n",
    "    #print(\"-\"*70)\n",
    "    \n",
    "    count_rule3 = 0\n",
    "    \n",
    "    # Find 'item' header column / æŸ¥æ‰¾'item'è¡¨å¤´åˆ—\n",
    "    item_headers = df[(df['mark'] == 'header') & \n",
    "                     (df['text'].str.upper().str.contains('ITEM|DESCRIPTION|DESC|PRODUCT|NAME', na=False))]\n",
    "    \n",
    "    if len(item_headers) > 0:\n",
    "        item_col = item_headers.iloc[0]['col_No']\n",
    "        item_header_text = item_headers.iloc[0]['text']\n",
    "        #print(f\"Found item header: '{item_header_text}' at col_No={item_col}\\n\")\n",
    "        \n",
    "        # Mark all text items in this column as priority=2\n",
    "        # å°†è¯¥åˆ—çš„æ‰€æœ‰texté¡¹æ ‡è®°ä¸ºpriority=2\n",
    "        for idx, row in df.iterrows():\n",
    "            if row['mark'] == 'text' and row['col_No'] == item_col and row['priority'] == 1:\n",
    "                df.loc[idx, 'priority'] = 2\n",
    "                count_rule3 += 1\n",
    "                \n",
    "                text_row = row['row_No']\n",
    "                print(f\"  âœ“ Text '{row['text'][:30]}' (row={text_row}, col={item_col}) â†’ priority=2\")\n",
    "                print(f\"    In same column as '{item_header_text}' header\")\n",
    "    else:\n",
    "        print(\"âŒNo 'item' header found / æœªæ‰¾åˆ°'item'è¡¨å¤´\")\n",
    "    \n",
    "    #print(f\"\\nRule 3 applied to {count_rule3} text items\")\n",
    "    \n",
    "    # #========== Final Summary / æœ€ç»ˆæ€»ç»“ ==========\n",
    "    # print(\"\\n\" + \"=\"*70)\n",
    "    # print(\"FINAL SUMMARY / æœ€ç»ˆæ€»ç»“:\")\n",
    "    # print(\"=\"*70)\n",
    "    \n",
    "    # priority_counts = df['priority'].value_counts().sort_index()\n",
    "    \n",
    "    # for val in [0, 1, 2]:\n",
    "    #     count = priority_counts.get(val, 0)\n",
    "    #     if val == 0:\n",
    "    #         print(f\"  priority = 0 (Invalid / æ— æ•ˆ): {count} items\")\n",
    "    #     elif val == 1:\n",
    "    #         print(f\"  priority = 1 (Normal valid / æ™®é€šæœ‰æ•ˆ): {count} items\")\n",
    "    #     elif val == 2:\n",
    "    #         print(f\"  priority = 2 (High priority / é«˜ä¼˜å…ˆçº§): {count} items\")\n",
    "    \n",
    "    # total_changes = count_rule1 + count_rule2 + count_rule3\n",
    "    # print(f\"\\nTotal items marked as priority=2: {total_changes}\")\n",
    "    # print(f\"æ ‡è®°ä¸ºpriority=2çš„æ€»é¡¹æ•°: {total_changes}\")\n",
    "    \n",
    "    # print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "#====================================================================================================\n",
    "def calculate_row_diff(df):\n",
    "    \"\"\"\n",
    "    Calculate row difference between price and text\n",
    "    è®¡ç®—priceå’Œtextä¹‹é—´çš„è¡Œå·®\n",
    "    \n",
    "    Logic:\n",
    "    1. Count the number of price and text entries to find unmatched extra rows\n",
    "    2. For the type with more entries, calculate row difference to nearest row of the other type\n",
    "    3. Store row differences in row_diff column\n",
    "    \n",
    "    é€»è¾‘ï¼š\n",
    "    1. ç»Ÿè®¡priceå’Œtextæ•°é‡ï¼Œå¾—åˆ°ä¸èƒ½åŒ¹é…çš„å¤šä½™è¡Œæ•°\n",
    "    2. å¯¹æ•°é‡å¤šçš„ç±»å‹ï¼Œè®¡ç®—æœ€è¿‘è¡Œçš„å¦ä¸€ç§ç±»å‹çš„è¡Œå·®å€¼\n",
    "    3. å°†è¡Œå·®å­˜åˆ°row_diffåˆ—\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"CALCULATING ROW DIFFERENCES / è®¡ç®—è¡Œå·®:\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Filter priority=2 and mark in ['text', 'price'] \n",
    "    # ç­›é€‰priority=2ä¸”markä¸ºtextæˆ–price\n",
    "    filtered = df[(df['priority'] == 2) & \n",
    "                  (df['mark'].isin(['text', 'price']))]\n",
    "    \n",
    "    # Count text and price / ç»Ÿè®¡textå’Œpriceæ•°é‡\n",
    "    text_count = len(filtered[filtered['mark'] == 'text'])\n",
    "    price_count = len(filtered[filtered['mark'] == 'price'])\n",
    "    \n",
    "    #print(f\"Text count: {text_count}\")\n",
    "    #print(f\"Price count: {price_count}\")\n",
    "    \n",
    "    # Initialize row_diff column / åˆå§‹åŒ–row_diffåˆ—\n",
    "    filtered['row_diff'] = None\n",
    "    \n",
    "    # Determine which is more / åˆ¤æ–­å“ªä¸ªæ•°é‡å¤š\n",
    "    need_to_delete = 0\n",
    "    \n",
    "    if price_count > text_count:\n",
    "        #print(f\"\\nâœ“ Price is more numerous / Priceæ•°é‡æ›´å¤š\")\n",
    "        #print(f\"For each price, finding nearest text / å¯¹æ¯ä¸ªpriceæŸ¥æ‰¾æœ€è¿‘çš„text\\n\")\n",
    "        \n",
    "        search_type = 'price'\n",
    "        target_type = 'text'\n",
    "        need_to_delete = price_count - text_count\n",
    "        \n",
    "    elif text_count > price_count:\n",
    "        #print(f\"\\nâœ“ Text is more numerous / Textæ•°é‡æ›´å¤š\")\n",
    "        #print(f\"For each text, finding nearest price / å¯¹æ¯ä¸ªtextæŸ¥æ‰¾æœ€è¿‘çš„price\\n\")\n",
    "        \n",
    "        search_type = 'text'\n",
    "        target_type = 'price'\n",
    "        need_to_delete = text_count - price_count\n",
    "    else:\n",
    "        #print(f\"\\nâŒ  Equal count, defaulting to search from price / æ•°é‡ç›¸ç­‰ï¼Œé»˜è®¤ä»priceæœç´¢\")\n",
    "        search_type = 'price'\n",
    "        target_type = 'text'\n",
    "    \n",
    "    # Process each item / å¤„ç†æ¯ä¸ªæ¡ç›®\n",
    "    count = 0\n",
    "    \n",
    "    for idx in filtered.index:\n",
    "        # Check if this is the search type\n",
    "        if filtered.loc[idx, 'priority'] == 2 and filtered.loc[idx, 'mark'] == search_type:\n",
    "            current_row = filtered.loc[idx, 'row_No']\n",
    "            current_text = filtered.loc[idx, 'text']\n",
    "            \n",
    "            # Find nearest target type / æŸ¥æ‰¾æœ€è¿‘çš„ç›®æ ‡ç±»å‹\n",
    "            min_diff = float('inf')\n",
    "            nearest_target = None\n",
    "            \n",
    "            for idx2 in filtered.index:\n",
    "                if filtered.loc[idx2, 'priority'] == 2 and filtered.loc[idx2, 'mark'] == target_type:\n",
    "                    target_row = filtered.loc[idx2, 'row_No']\n",
    "                    diff = abs(target_row - current_row)\n",
    "                    \n",
    "                    # Update if closer / å¦‚æœæ›´è¿‘åˆ™æ›´æ–°\n",
    "                    if diff < min_diff:\n",
    "                        min_diff = diff\n",
    "                        nearest_target = {\n",
    "                            'idx': idx2,\n",
    "                            'row': target_row,\n",
    "                            'text': filtered.loc[idx2, 'text']\n",
    "                        }\n",
    "            \n",
    "            # Store the difference / å­˜å‚¨å·®å€¼\n",
    "            if nearest_target:\n",
    "                # Calculate signed difference / è®¡ç®—å¸¦ç¬¦å·çš„å·®å€¼\n",
    "                actual_diff = nearest_target['row'] - current_row\n",
    "                filtered.loc[idx, 'row_diff'] = actual_diff\n",
    "                count += 1\n",
    "                \n",
    "                if actual_diff == 0:\n",
    "                    direction = \"same row / åŒä¸€è¡Œ\"\n",
    "                elif actual_diff > 0:\n",
    "                    direction = f\"{actual_diff} rows below / ä¸‹æ–¹{actual_diff}è¡Œ\"\n",
    "                else:\n",
    "                    direction = f\"{abs(actual_diff)} rows above / ä¸Šæ–¹{abs(actual_diff)}è¡Œ\"\n",
    "                \n",
    "                #print(f\"  {search_type.upper()} '{current_text}' (row={current_row})\")\n",
    "                #print(f\"    â†’ Nearest {target_type}: '{nearest_target['text']}' (row={nearest_target['row']})\")\n",
    "                #print(f\"    â†’ row_diff = {actual_diff} ({direction})\\n\")\n",
    "            else:\n",
    "                filtered.loc[idx, 'row_diff'] = None\n",
    "                #print(f\"  {search_type.upper()} '{current_text}' (row={current_row})\")\n",
    "                #print(f\"    â†’ No {target_type} found\\n\")\n",
    "    \n",
    "    #print(\"=\"*70)\n",
    "    #print(f\"âœ… Calculated row_diff for {count} items\")\n",
    "    #print(f\"âœ… ä¸º{count}é¡¹è®¡ç®—äº†row_diff\")\n",
    "    #print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return filtered, need_to_delete\n",
    "#====================================================================================================\n",
    "def delete_by_row_diff(df, need_to_delete):\n",
    "    \"\"\"\n",
    "    Delete extra rows based on row_diff distribution\n",
    "    æ ¹æ® row_diff åˆ†å¸ƒåˆ é™¤å¤šä½™è¡Œ\n",
    "    \n",
    "    Logic:\n",
    "    1. Count row_diff value distribution\n",
    "    2. Delete rows with least frequent and largest absolute difference\n",
    "    3. Repeat until deleted need_to_delete rows\n",
    "    \n",
    "    é€»è¾‘ï¼š\n",
    "    1. ç»Ÿè®¡row_diffå€¼çš„åˆ†å¸ƒ\n",
    "    2. åˆ é™¤æ•°é‡æœ€å°‘ä¸”å·®å€¼æœ€å¤§çš„row_diffæ‰€åœ¨çš„è¡Œ\n",
    "    3. é‡å¤ç›´åˆ°åˆ é™¤äº†need_to_deleteè¡Œ\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"DELETING ROWS BY ROW_DIFF / æ ¹æ®row_diffåˆ é™¤è¡Œ:\")\n",
    "    #print(f\"Need to delete: {need_to_delete} rows\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Get rows that have row_diff / è·å–æœ‰row_diffçš„è¡Œ\n",
    "    rows_with_diff = df[df['row_diff'].notna()].copy()\n",
    "    \n",
    "    if len(rows_with_diff) == 0:\n",
    "        print(\"âŒ No rows with row_diff to delete\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "        return df\n",
    "    \n",
    "    #print(f\"Total rows with row_diff: {len(rows_with_diff)}\")\n",
    "    \n",
    "    # Track deleted indices / è¿½è¸ªè¦åˆ é™¤çš„ç´¢å¼•\n",
    "    to_delete_indices = []\n",
    "    deleted_count = 0\n",
    "    \n",
    "    # Loop until we've deleted enough rows / å¾ªç¯ç›´åˆ°åˆ é™¤è¶³å¤Ÿçš„è¡Œ\n",
    "    while deleted_count < need_to_delete:\n",
    "        # Get current row_diff distribution (excluding already marked for deletion)\n",
    "        # è·å–å½“å‰row_diffåˆ†å¸ƒï¼ˆæ’é™¤å·²æ ‡è®°åˆ é™¤çš„ï¼‰\n",
    "        remaining = rows_with_diff[~rows_with_diff.index.isin(to_delete_indices)]\n",
    "        \n",
    "        if len(remaining) == 0:\n",
    "            print(f\"\\nâŒ No more rows to delete (deleted {deleted_count}/{need_to_delete})\")\n",
    "            break\n",
    "        \n",
    "        # Count distribution / ç»Ÿè®¡åˆ†å¸ƒ\n",
    "        diff_counts = remaining['row_diff'].value_counts()\n",
    "        \n",
    "        #print(f\"\\nIteration {deleted_count + 1}:\")\n",
    "        #print(f\"Current row_diff distribution / å½“å‰row_diffåˆ†å¸ƒ:\")\n",
    "        #for diff_val, count in diff_counts.sort_index().items():\n",
    "            #print(f\"  row_diff={diff_val:3}: {count} items\")\n",
    "        \n",
    "        # Find minimum count / æ‰¾åˆ°æœ€å°æ•°é‡\n",
    "        min_count = diff_counts.min()\n",
    "        #print(f\"\\nMinimum count: {min_count}\")\n",
    "        \n",
    "\n",
    "        # Get all row_diff values with minimum count / è·å–æ‰€æœ‰æœ€å°æ•°é‡çš„row_diffå€¼\n",
    "        min_count_diffs = diff_counts[diff_counts == min_count].index.tolist()\n",
    "        #print(f\"Row_diff values with min count: {min_count_diffs}\")\n",
    "        \n",
    "        # Among these, find the one with largest absolute value / å…¶ä¸­æ‰¾åˆ°ç»å¯¹å€¼æœ€å¤§çš„\n",
    "        max_abs_diff = max(min_count_diffs, key=abs)\n",
    "        #print(f\"Largest absolute difference: {max_abs_diff}\")\n",
    "        \n",
    "        # Get rows with this row_diff value / è·å–è¿™ä¸ªrow_diffå€¼çš„è¡Œ\n",
    "        rows_to_delete = remaining[remaining['row_diff'] == max_abs_diff]\n",
    "        \n",
    "        #print(f\"\\nDeleting {len(rows_to_delete)} row(s) with row_diff={max_abs_diff}:\")\n",
    "        \n",
    "        # Delete these rows (or as many as needed) / åˆ é™¤è¿™äº›è¡Œ\n",
    "        for idx in rows_to_delete.index:\n",
    "            if deleted_count >= need_to_delete:\n",
    "                break\n",
    "            \n",
    "            to_delete_indices.append(idx)\n",
    "            deleted_count += 1\n",
    "            \n",
    "            row_no = df.loc[idx, 'row_No']\n",
    "            text = df.loc[idx, 'text']\n",
    "            mark = df.loc[idx, 'mark']\n",
    "            \n",
    "            #print(f\"  - Index {idx}: '{text}' (row={row_no}, mark={mark})\")\n",
    "    \n",
    "    # Actually delete from DataFrame / çœŸæ­£ä»DataFrameåˆ é™¤\n",
    "    df = df.drop(to_delete_indices).reset_index(drop=True)\n",
    "    \n",
    "    #print(f\"âœ… Deleted {deleted_count} rows\")\n",
    "    #print(f\"Remaining rows: {len(df)}\")\n",
    "    #print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "#====================================================================================================\n",
    "def create_matched_dataframe(df):\n",
    "    \"\"\"\n",
    "    Create final DataFrame with matched items and prices\n",
    "    åˆ›å»ºæœ€ç»ˆçš„é…å¯¹DataFrame\n",
    "    \n",
    "    Columns: item, price\n",
    "    Each row is a matched pair\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"CREATING MATCHED DATAFRAME / åˆ›å»ºé…å¯¹DataFrame:\")\n",
    "    print(\"=\"*70)\n",
    "    # Add row_match column / å¢åŠ ä¸€åˆ—row_match\n",
    "    # å¦‚æœrow_diffä¸ºnoneçš„ç›´æ¥ç”¨row_Noçš„å€¼ï¼Œå¦åˆ™row_NoåŠ ä¸Šrow_diff\n",
    "    df['row_match'] = df.apply(lambda row: row['row_No'] if pd.isna(row['row_diff']) else row['row_No'] + row['row_diff'], axis=1).astype(int)\n",
    "    \n",
    "    # Get unique row_match values / è·å–å”¯ä¸€çš„row_matchå€¼\n",
    "    unique_matches = df['row_match'].unique()\n",
    "    unique_matches = sorted(unique_matches)\n",
    "    \n",
    "    #print(f\"Total unique row_match values: {len(unique_matches)}\")\n",
    "    #print(f\"å”¯ä¸€row_matchå€¼æ€»æ•°: {len(unique_matches)}\\n\")\n",
    "    \n",
    "    # Store matched pairs / å­˜å‚¨é…å¯¹ç»“æœ\n",
    "    matched_list = []\n",
    "    \n",
    "    # Process each row_match value / å¤„ç†æ¯ä¸ªrow_matchå€¼\n",
    "    for match_value in unique_matches:\n",
    "        # Get all rows with this row_match / è·å–è¯¥row_matchçš„æ‰€æœ‰è¡Œ\n",
    "        matched_rows = df[df['row_match'] == match_value]\n",
    "        \n",
    "        # Find text and price / æŸ¥æ‰¾textå’Œprice\n",
    "        texts = matched_rows[matched_rows['mark'] == 'text']\n",
    "        prices = matched_rows[matched_rows['mark'] == 'price']\n",
    "        \n",
    "        # Only add if both text and price exist / åªæœ‰ä¸¤è€…éƒ½å­˜åœ¨æ—¶æ‰æ·»åŠ \n",
    "        if len(texts) > 0 and len(prices) > 0:\n",
    "            # Get first text and first price / å–ç¬¬ä¸€ä¸ªtextå’Œç¬¬ä¸€ä¸ªprice\n",
    "            item_text = texts.iloc[0]['text']\n",
    "            price_text = prices.iloc[0]['text']\n",
    "            \n",
    "            # Add to list / æ·»åŠ åˆ°åˆ—è¡¨\n",
    "            matched_list.append({\n",
    "                'item': item_text,\n",
    "                'price': price_text\n",
    "            })\n",
    "            \n",
    "            #print(f\"âœ… Matched (row_match={match_value}):\")\n",
    "            #print(f\"     Item: {item_text}\")\n",
    "            #print(f\"     Price: {price_text}\")\n",
    "        else:\n",
    "            #print(f\" âš ï¸ Skipped (row_match={match_value}): \", end=\"\")\n",
    "            if len(texts) == 0:\n",
    "                print(f\"No text found\")\n",
    "            elif len(prices) == 0:\n",
    "                print(f\"No price found (has text: '{texts.iloc[0]['text']}')\")\n",
    "    \n",
    "    # Create final DataFrame / åˆ›å»ºæœ€ç»ˆDataFrame\n",
    "    final_df = pd.DataFrame(matched_list)\n",
    "    \n",
    "    print(\"FINAL MATCHED DATAFRAME / æœ€ç»ˆé…å¯¹DataFrame:\")\n",
    "    print(f\"Total matched pairs: {len(final_df)}\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4235d009-179d-4c23-9165-f1f23060b557",
   "metadata": {},
   "source": [
    "# PART 4: Interactive Visualization\n",
    "# ç¬¬å››éƒ¨åˆ†ï¼šäº¤äº’å¼å¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d5242c7-b273-41df-ae2d-9365ccf4ad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_interactive_viewer(receipt):\n",
    "    \"\"\"Interactive viewer with Add function / å¸¦æ–°å¢åŠŸèƒ½çš„äº¤äº’å¼æŸ¥çœ‹å™¨\"\"\"\n",
    "    \n",
    "    items = receipt['items']\n",
    "    \n",
    "    if len(items) == 0:\n",
    "        df = pd.DataFrame(columns=['Item', 'Price'])  # åˆ›å»ºç©ºè¡¨æ ¼\n",
    "        print(\"âš ï¸  No items detected, showing empty template\")\n",
    "    \n",
    "    df = pd.DataFrame(items)\n",
    "    original_df = df.copy()\n",
    "    \n",
    "    # Receipt ID\n",
    "    if not hasattr(create_interactive_viewer, 'counter'):\n",
    "        create_interactive_viewer.counter = {}\n",
    "    \n",
    "    date = receipt.get('date', 'Unknown')\n",
    "    if date not in create_interactive_viewer.counter:\n",
    "        create_interactive_viewer.counter[date] = 0\n",
    "    create_interactive_viewer.counter[date] += 1\n",
    "    receipt_id = create_interactive_viewer.counter[date]\n",
    "    \n",
    "    # ========== Calculate Total / è®¡ç®—æ€»é¢ ==========\n",
    "    def calculate_total(dataframe):\n",
    "        total = 0.0\n",
    "        for idx, row in dataframe.iterrows():\n",
    "            price_str = str(row['Price']).replace('$', '').strip()\n",
    "            try:\n",
    "                total += float(price_str)\n",
    "            except:\n",
    "                pass\n",
    "        return total\n",
    "    \n",
    "    # ========== Display Header / æ˜¾ç¤ºè¡¨å¤´ ==========\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"               ğŸ“‹ RECEIPT VIEWER / æ”¶æ®æŸ¥çœ‹å™¨\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nğŸ“… Date / æ—¥æœŸ: {receipt['date']}\")\n",
    "    print(f\"ğŸ†” Receipt ID / æ”¶æ®ç¼–å·: #{receipt_id}\")\n",
    "    print(f\"ğŸ“¦ Total Items / å•†å“æ€»æ•°: {len(items)}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"                    ğŸ“ ITEMS LIST / å•†å“åˆ—è¡¨\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # ========== Display Table / æ˜¾ç¤ºè¡¨æ ¼ ==========\n",
    "    table_output = widgets.Output()\n",
    "    \n",
    "    def refresh_table():\n",
    "        \"\"\"Refresh table display / åˆ·æ–°è¡¨æ ¼æ˜¾ç¤º\"\"\"\n",
    "        display_df = df.copy()\n",
    "        display_df.index = range(1, len(df) + 1)\n",
    "        with table_output:\n",
    "            clear_output()\n",
    "            display(display_df)\n",
    "    \n",
    "    refresh_table()\n",
    "    display(table_output)\n",
    "    \n",
    "    # ========== Dynamic Total / åŠ¨æ€æ€»é¢ ==========\n",
    "    total_output = widgets.Output()\n",
    "    \n",
    "    def update_total_display():\n",
    "        new_total = calculate_total(df)\n",
    "        with total_output:\n",
    "            clear_output()\n",
    "            print()\n",
    "            print(\"=\"*70)\n",
    "            print(f\"{'ğŸ’° TOTAL / æ€»é¢:':>50} ${new_total:>8.2f}\")\n",
    "            print(\"=\"*70)\n",
    "    \n",
    "    update_total_display()\n",
    "    display(total_output)\n",
    "    \n",
    "    # ========== Edit Section / ç¼–è¾‘åŒºåŸŸ ==========\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"                âœï¸  EDIT DATA / ç¼–è¾‘æ•°æ®\")\n",
    "    print(\"-\"*70 + \"\\n\")\n",
    "    \n",
    "    row_input = widgets.IntText(value=1, description='Row / è¡Œå·:', min=1)\n",
    "    item_input = widgets.Text(value='', description='Item / å•†å“:', placeholder='Item name', layout=widgets.Layout(width='400px'))\n",
    "    price_input = widgets.Text(value='', description='Price / ä»·æ ¼:', placeholder='0.00')\n",
    "    \n",
    "    add_btn = widgets.Button(description='âœš Add / æ–°å¢', button_style='success', icon='plus')\n",
    "    update_btn = widgets.Button(description='âœ“ Update / æ›´æ–°', button_style='info', icon='check')\n",
    "    delete_btn = widgets.Button(description='âœ— Delete / åˆ é™¤', button_style='danger', icon='trash')\n",
    "    reset_btn = widgets.Button(description='â†º Reset / é‡ç½®', button_style='warning', icon='refresh')\n",
    "    save_btn = widgets.Button(description='ğŸ’¾ Export CSV / å¯¼å‡º', button_style='primary', icon='download')\n",
    "    \n",
    "    status_output = widgets.Output()\n",
    "    \n",
    "    # ========== Button Functions / æŒ‰é’®åŠŸèƒ½ ==========\n",
    "    \n",
    "    def on_add(b):\n",
    "        \"\"\"Add new item / æ–°å¢å•†å“\"\"\"\n",
    "        nonlocal df\n",
    "        with status_output:\n",
    "            clear_output()\n",
    "            \n",
    "            # Check if item and price are provided\n",
    "            if not item_input.value or not price_input.value:\n",
    "                print(\"âŒ Please enter both item and price!\")\n",
    "                print(\"âŒ è¯·è¾“å…¥å•†å“åå’Œä»·æ ¼ï¼\")\n",
    "                return\n",
    "            \n",
    "            # Create new row / åˆ›å»ºæ–°è¡Œ\n",
    "            new_item = {\n",
    "                'Item': item_input.value,\n",
    "                'Price': price_input.value\n",
    "            }\n",
    "            \n",
    "            # Add to DataFrame / æ·»åŠ åˆ°DataFrame\n",
    "            df.loc[len(df)] = new_item\n",
    "            \n",
    "            # Update row_input max value\n",
    "            row_input.max = len(df)\n",
    "            \n",
    "            # Refresh display\n",
    "            refresh_table()\n",
    "            update_total_display()\n",
    "            \n",
    "            print(f\"âœ… New item added! / æ–°å•†å“å·²æ·»åŠ ï¼\")\n",
    "            print(f\"   Item: {item_input.value}\")\n",
    "            print(f\"   Price: {price_input.value}\")\n",
    "            print(f\"   Total rows: {len(df)}\")\n",
    "            \n",
    "            # Clear inputs / æ¸…ç©ºè¾“å…¥æ¡†\n",
    "            item_input.value = ''\n",
    "            price_input.value = ''\n",
    "    \n",
    "    def on_update(b):\n",
    "        \"\"\"Update existing item / æ›´æ–°ç°æœ‰å•†å“\"\"\"\n",
    "        nonlocal df\n",
    "        with status_output:\n",
    "            clear_output()\n",
    "            row = row_input.value\n",
    "            actual_idx = row - 1\n",
    "            \n",
    "            if 0 <= actual_idx < len(df):\n",
    "                if item_input.value:\n",
    "                    df.at[actual_idx, 'Item'] = item_input.value\n",
    "                if price_input.value:\n",
    "                    df.at[actual_idx, 'Price'] = price_input.value\n",
    "                \n",
    "                refresh_table()\n",
    "                update_total_display()\n",
    "                print(f\"âœ… Row {row} updated! / ç¬¬{row}è¡Œå·²æ›´æ–°ï¼\")\n",
    "            else:\n",
    "                print(f\"âŒ Row {row} does not exist! / ç¬¬{row}è¡Œä¸å­˜åœ¨ï¼\")\n",
    "                print(f\"   Valid range: 1-{len(df)}\")\n",
    "    \n",
    "    def on_delete(b):\n",
    "        \"\"\"Delete item / åˆ é™¤å•†å“\"\"\"\n",
    "        nonlocal df\n",
    "        with status_output:\n",
    "            clear_output()\n",
    "            row = row_input.value\n",
    "            actual_idx = row - 1\n",
    "            \n",
    "            if 0 <= actual_idx < len(df):\n",
    "                deleted_item = df.loc[actual_idx, 'Item']\n",
    "                df = df.drop(actual_idx).reset_index(drop=True)\n",
    "                \n",
    "                row_input.max = len(df) if len(df) > 0 else 1\n",
    "                \n",
    "                refresh_table()\n",
    "                update_total_display()\n",
    "                print(f\"âœ… Row {row} deleted! / ç¬¬{row}è¡Œå·²åˆ é™¤ï¼\")\n",
    "                print(f\"   Deleted: {deleted_item}\")\n",
    "            else:\n",
    "                print(f\"âŒ Row {row} does not exist!\")\n",
    "    \n",
    "    def on_reset(b):\n",
    "        \"\"\"Reset to original / é‡ç½®ä¸ºåŸå§‹æ•°æ®\"\"\"\n",
    "        nonlocal df\n",
    "        with status_output:\n",
    "            clear_output()\n",
    "            df = original_df.copy()\n",
    "            \n",
    "            row_input.max = len(df)\n",
    "            \n",
    "            refresh_table()\n",
    "            update_total_display()\n",
    "            print(\"âœ… Data reset! / æ•°æ®å·²é‡ç½®ï¼\")\n",
    "    \n",
    "    def on_save(b):\n",
    "        \"\"\"Export to CSV / å¯¼å‡ºä¸ºCSV\"\"\"\n",
    "        with status_output:\n",
    "            clear_output()\n",
    "            \n",
    "            final_total = calculate_total(df)\n",
    "            export_data = []\n",
    "            \n",
    "            for idx, row in df.iterrows():\n",
    "                price_str = str(row['Price']).replace('$', '').strip()\n",
    "                try:\n",
    "                    cost = float(price_str)\n",
    "                except:\n",
    "                    cost = 0.0\n",
    "                \n",
    "                export_data.append({\n",
    "                    'Date': receipt['date'],\n",
    "                    'id': receipt_id,\n",
    "                    'Item': row['Item'],\n",
    "                    'cost': f\"${cost:.2f}\",\n",
    "                    'total': f\"${final_total:.2f}\"\n",
    "                })\n",
    "            \n",
    "            export_df = pd.DataFrame(export_data)\n",
    "            date_str = receipt['date'].replace('/', '-')\n",
    "            filename = f'receipt_{date_str}_id{receipt_id}.csv'\n",
    "            export_df.to_csv(filename, index=False)\n",
    "            \n",
    "            print(f\"âœ… Exported to: {filename}\")\n",
    "            print(f\"ğŸ“Š Total: ${final_total:.2f}\")\n",
    "    \n",
    "    # Connect buttons\n",
    "    add_btn.on_click(on_add)\n",
    "    update_btn.on_click(on_update)\n",
    "    delete_btn.on_click(on_delete)\n",
    "    reset_btn.on_click(on_reset)\n",
    "    save_btn.on_click(on_save)\n",
    "    \n",
    "    # Display widgets\n",
    "    display(row_input)\n",
    "    display(item_input)\n",
    "    display(price_input)\n",
    "    display(widgets.HBox([add_btn, update_btn, delete_btn, reset_btn, save_btn]))\n",
    "    display(status_output)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ“– Instructions / ä½¿ç”¨è¯´æ˜:\")\n",
    "    print(\"-\"*70)\n",
    "    print(\"1. Add / æ–°å¢: Enter item and price, click Add\")\n",
    "    print(\"   è¾“å…¥å•†å“åå’Œä»·æ ¼ï¼Œç‚¹å‡»æ–°å¢\")\n",
    "    print(\"2. Update / æ›´æ–°: Enter row number and new values, click Update\")\n",
    "    print(\"   è¾“å…¥è¡Œå·å’Œæ–°å€¼ï¼Œç‚¹å‡»æ›´æ–°\")\n",
    "    print(\"3. Delete / åˆ é™¤: Enter row number, click Delete\")\n",
    "    print(\"   è¾“å…¥è¡Œå·ï¼Œç‚¹å‡»åˆ é™¤\")\n",
    "    print(\"4. Reset / é‡ç½®: Restore original data\")\n",
    "    print(\"   æ¢å¤åŸå§‹æ•°æ®\")\n",
    "    print(\"5. Export CSV / å¯¼å‡º: Save to file\")\n",
    "    print(\"   ä¿å­˜ä¸ºæ–‡ä»¶\")\n",
    "    print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193cd67b-a8bb-4397-84a2-c141d3841250",
   "metadata": {},
   "source": [
    "# PART 5: Main Processing Function\n",
    "# ç¬¬äº”éƒ¨åˆ†ï¼šä¸»å¤„ç†å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbc554af-d55b-48ac-8277-9148296c64e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process1_getdata(image_path, show_viewer=True):\n",
    "    \"\"\"\n",
    "    Main function to process a receipt\n",
    "    ä¸»å‡½æ•°ï¼Œç”¨äºå¤„ç†æ”¶æ®\n",
    "    \n",
    "    Args:\n",
    "        image_path: path to receipt image / æ”¶æ®å›¾åƒè·¯å¾„\n",
    "        show_viewer: whether to show interactive viewer / æ˜¯å¦æ˜¾ç¤ºäº¤äº’å¼æŸ¥çœ‹å™¨\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"Processing: {os.path.basename(image_path)}\")\n",
    "    print(f\"å¤„ç†: {os.path.basename(image_path)}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Preprocess / é¢„å¤„ç†\n",
    "    print(\"Step 1: Preprocessing... / æ­¥éª¤1ï¼šé¢„å¤„ç†...\")\n",
    "    preprocessed = preprocess_image(image_path)\n",
    "    if preprocessed is None:\n",
    "        print(\"âŒ Preprocessing failed!\")\n",
    "        return None\n",
    "    print(\"âœ… Preprocessing done\")\n",
    "    \n",
    "    # OCR / OCRè¯†åˆ«\n",
    "    print(\"\\nStep 2: OCR Recognition... / æ­¥éª¤2ï¼šOCRè¯†åˆ«...\")\n",
    "    ocr = initialize_ocr()\n",
    "    ocr_result = perform_ocr(ocr, image_path)\n",
    "    #print(\"ocr_result:\", ocr_result)\n",
    "    #print(f\"Keys in result: {list(ocr_result.keys())}\")\n",
    "\n",
    "    if len(ocr_result) == 0:\n",
    "        print(\"âŒ No text detected!\")\n",
    "        return None\n",
    "    print(f\"âœ… Detected {len(ocr_result)} text regions\")\n",
    "\n",
    "    # Organize / æ•´ç†\n",
    "    print(\"\\nStep 3: Organizing data... / æ­¥éª¤3ï¼šæ•´ç†æ•°æ®...\")\n",
    "    df_ocr_result = organize_ocr_results(ocr_result)\n",
    "    print(\"âœ… Data organized\")\n",
    "\n",
    "    return df_ocr_result\n",
    "\n",
    "def process2_get_main_information(df_ocr_result):\n",
    "    print(\"\\nStep 4: Extracting information... / æ­¥éª¤4ï¼šæå–ä¿¡æ¯...\")\n",
    "    print(\"ADDING MARK COLUMN / æ·»åŠ æ ‡è®°åˆ†ç±»:\")\n",
    "    print(\"=\"*70)  \n",
    "\n",
    "    #ç²—ç•¥æ ‡è®°æ–‡æœ¬åˆ†ç±»\n",
    "    df_ocr_result['mark'] = df_ocr_result['text'].apply(classify_text_type)\n",
    "\n",
    "    #è·å–æ—¥æœŸ\n",
    "    date_rows = df_ocr_result[df_ocr_result['mark'] == 'date']\n",
    "    if len(date_rows) > 0:\n",
    "        date_str = date_rows['text'].iloc[0]\n",
    "    else:\n",
    "        date_str = \"Date not found\"\n",
    "    \n",
    "    #å¢åŠ è¡Œå·\n",
    "    df_mark_data =  mark_row_number(df_ocr_result)\n",
    "\n",
    "    #è¯†åˆ«æœ‰æ•ˆä¿¡æ¯è¡¨æ ¼éƒ¨åˆ†ï¼Œæƒé‡è®¾ç½®ä¸º1\n",
    "    df_mark_data = add_priority_column(df_mark_data)\n",
    "    df_valid_data = df_ocr_result[df_mark_data['priority'] == 1].copy()\n",
    "\n",
    "    #å¢åŠ åˆ—å·\n",
    "    df_valid_data = add_column_number(df_valid_data)\n",
    "\n",
    "    #æ‰¾å‡ºâ€œå•ä½â€çš„æ–‡æœ¬\n",
    "    df_valid_data = mark_units(df_valid_data)\n",
    "\n",
    "    #è¿›ä¸€æ­¥è¯†åˆ«æœ‰æ•ˆä¿¡æ¯ï¼Œæƒé‡è®¾ç½®ä¸º2\n",
    "    df_valid_data = update_priority_marks(df_valid_data)\n",
    "\n",
    "    #è®¡ç®—ç›®æ ‡ä¿¡æ¯çš„è¡Œå·®å€¼ï¼Œç”¨ä½œåç»­çš„ä¿¡æ¯åŒ¹é…\n",
    "    df_goal_data,need_to_delete = calculate_row_diff(df_valid_data)\n",
    "    \n",
    "    #åˆ é™¤åŒ¹é…ä¸åˆ°çš„å¤šä½™ä¿¡æ¯\n",
    "    df_goal_data = delete_by_row_diff(df_goal_data, need_to_delete)\n",
    "\n",
    "    #è·å–åŒ¹é…å¥½çš„ä¿¡æ¯\n",
    "    df_matched_goal_data = create_matched_dataframe(df_goal_data)\n",
    "\n",
    "    print(\"âœ… Target information extraction completed\")    \n",
    "    return date_str, df_mark_data, df_valid_data, df_goal_data, df_matched_goal_data\n",
    "\n",
    "    \n",
    "\n",
    "def process3_display(df):\n",
    "    if show_viewer and len(items) > 0:\n",
    "        print(\"\\nStep 5: Creating viewer... / æ­¥éª¤5ï¼šåˆ›å»ºæŸ¥çœ‹å™¨...\")\n",
    "        create_interactive_viewer(receipt_info)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2299fb-673d-4c23-af77-cce35fd1430a",
   "metadata": {},
   "source": [
    "# Entry point / ä»£ç è¿è¡Œå…¥å£â¬‡ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f3c340c-0026-42c4-bba5-fb8b95ab4aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Processing: X00016469672.jpg\n",
      "å¤„ç†: X00016469672.jpg\n",
      "======================================================================\n",
      "Step 1: Preprocessing... / æ­¥éª¤1ï¼šé¢„å¤„ç†...\n",
      "âœ… Preprocessing done\n",
      "\n",
      "Step 2: OCR Recognition... / æ­¥éª¤2ï¼šOCRè¯†åˆ«...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/Users/chiara/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('UVDoc', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/Users/chiara/.paddlex/official_models/UVDoc`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/Users/chiara/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/Users/chiara/.paddlex/official_models/PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('en_PP-OCRv5_mobile_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/Users/chiara/.paddlex/official_models/en_PP-OCRv5_mobile_rec`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Detected 15 text regions\n",
      "\n",
      "Step 3: Organizing data... / æ­¥éª¤3ï¼šæ•´ç†æ•°æ®...\n",
      "ORGANIZING OCR DATA / æ•´ç†OCRæ•°æ®:\n",
      "======================================================================\n",
      "âœ… Data organized\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>confidence</th>\n",
       "      <th>left_top_x</th>\n",
       "      <th>left_top_y</th>\n",
       "      <th>right_top_x</th>\n",
       "      <th>right_top_y</th>\n",
       "      <th>left_bottom_x</th>\n",
       "      <th>left_bottom_y</th>\n",
       "      <th>right_bottom_x</th>\n",
       "      <th>right_bottom_y</th>\n",
       "      <th>center_x</th>\n",
       "      <th>center_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tan chay yee</td>\n",
       "      <td>0.991900</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>316</td>\n",
       "      <td>0</td>\n",
       "      <td>316</td>\n",
       "      <td>33</td>\n",
       "      <td>97</td>\n",
       "      <td>33</td>\n",
       "      <td>206.5</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOON HUAT MACHINERY ENTERPRISE</td>\n",
       "      <td>0.984482</td>\n",
       "      <td>19</td>\n",
       "      <td>53</td>\n",
       "      <td>431</td>\n",
       "      <td>61</td>\n",
       "      <td>430</td>\n",
       "      <td>88</td>\n",
       "      <td>18</td>\n",
       "      <td>80</td>\n",
       "      <td>224.5</td>\n",
       "      <td>70.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(JM0352019-K)</td>\n",
       "      <td>0.974050</td>\n",
       "      <td>160</td>\n",
       "      <td>79</td>\n",
       "      <td>294</td>\n",
       "      <td>82</td>\n",
       "      <td>293</td>\n",
       "      <td>110</td>\n",
       "      <td>159</td>\n",
       "      <td>107</td>\n",
       "      <td>226.5</td>\n",
       "      <td>94.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NO.53 JALAN PUTRA 1.</td>\n",
       "      <td>0.971054</td>\n",
       "      <td>127</td>\n",
       "      <td>107</td>\n",
       "      <td>327</td>\n",
       "      <td>110</td>\n",
       "      <td>326</td>\n",
       "      <td>135</td>\n",
       "      <td>126</td>\n",
       "      <td>131</td>\n",
       "      <td>226.5</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TAMAN SRI PUTRA.</td>\n",
       "      <td>0.994149</td>\n",
       "      <td>142</td>\n",
       "      <td>133</td>\n",
       "      <td>312</td>\n",
       "      <td>135</td>\n",
       "      <td>312</td>\n",
       "      <td>159</td>\n",
       "      <td>142</td>\n",
       "      <td>157</td>\n",
       "      <td>227.0</td>\n",
       "      <td>146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>327.00</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>354</td>\n",
       "      <td>1082</td>\n",
       "      <td>413</td>\n",
       "      <td>1082</td>\n",
       "      <td>413</td>\n",
       "      <td>1103</td>\n",
       "      <td>354</td>\n",
       "      <td>1103</td>\n",
       "      <td>383.5</td>\n",
       "      <td>1092.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>CASH :</td>\n",
       "      <td>0.990495</td>\n",
       "      <td>244</td>\n",
       "      <td>1113</td>\n",
       "      <td>323</td>\n",
       "      <td>1110</td>\n",
       "      <td>324</td>\n",
       "      <td>1135</td>\n",
       "      <td>244</td>\n",
       "      <td>1138</td>\n",
       "      <td>284.0</td>\n",
       "      <td>1124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>327.00</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>355</td>\n",
       "      <td>1114</td>\n",
       "      <td>414</td>\n",
       "      <td>1114</td>\n",
       "      <td>414</td>\n",
       "      <td>1134</td>\n",
       "      <td>355</td>\n",
       "      <td>1134</td>\n",
       "      <td>384.5</td>\n",
       "      <td>1124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Change :</td>\n",
       "      <td>0.991664</td>\n",
       "      <td>226</td>\n",
       "      <td>1139</td>\n",
       "      <td>322</td>\n",
       "      <td>1135</td>\n",
       "      <td>323</td>\n",
       "      <td>1160</td>\n",
       "      <td>227</td>\n",
       "      <td>1163</td>\n",
       "      <td>274.5</td>\n",
       "      <td>1149.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.999798</td>\n",
       "      <td>374</td>\n",
       "      <td>1137</td>\n",
       "      <td>415</td>\n",
       "      <td>1137</td>\n",
       "      <td>415</td>\n",
       "      <td>1159</td>\n",
       "      <td>374</td>\n",
       "      <td>1159</td>\n",
       "      <td>394.5</td>\n",
       "      <td>1148.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              text  confidence  left_top_x  left_top_y  \\\n",
       "0                     tan chay yee    0.991900          97           0   \n",
       "1   SOON HUAT MACHINERY ENTERPRISE    0.984482          19          53   \n",
       "2                    (JM0352019-K)    0.974050         160          79   \n",
       "3             NO.53 JALAN PUTRA 1.    0.971054         127         107   \n",
       "4                 TAMAN SRI PUTRA.    0.994149         142         133   \n",
       "..                             ...         ...         ...         ...   \n",
       "86                          327.00    0.999899         354        1082   \n",
       "87                          CASH :    0.990495         244        1113   \n",
       "88                          327.00    0.999916         355        1114   \n",
       "89                        Change :    0.991664         226        1139   \n",
       "90                            0.00    0.999798         374        1137   \n",
       "\n",
       "    right_top_x  right_top_y  left_bottom_x  left_bottom_y  right_bottom_x  \\\n",
       "0           316            0            316             33              97   \n",
       "1           431           61            430             88              18   \n",
       "2           294           82            293            110             159   \n",
       "3           327          110            326            135             126   \n",
       "4           312          135            312            159             142   \n",
       "..          ...          ...            ...            ...             ...   \n",
       "86          413         1082            413           1103             354   \n",
       "87          323         1110            324           1135             244   \n",
       "88          414         1114            414           1134             355   \n",
       "89          322         1135            323           1160             227   \n",
       "90          415         1137            415           1159             374   \n",
       "\n",
       "    right_bottom_y  center_x  center_y  \n",
       "0               33     206.5      16.5  \n",
       "1               80     224.5      70.5  \n",
       "2              107     226.5      94.5  \n",
       "3              131     226.5     121.0  \n",
       "4              157     227.0     146.0  \n",
       "..             ...       ...       ...  \n",
       "86            1103     383.5    1092.5  \n",
       "87            1138     284.0    1124.0  \n",
       "88            1134     384.5    1124.0  \n",
       "89            1163     274.5    1149.5  \n",
       "90            1159     394.5    1148.0  \n",
       "\n",
       "[91 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: OCR text extraction / è¿è¡Œæ­¥éª¤1ï¼šå›¾åƒè¯†åˆ«æå–æ–‡å­—\n",
    "\n",
    "\n",
    "# Input image path / è¾“å…¥å›¾ç‰‡è·¯å¾„\n",
    "#image_path = 'SROIE2019/train/img/X00016469612.jpg'\n",
    "image_path = 'SROIE2019/train/img/X00016469672.jpg'\n",
    "#image_path = 'SROIE2019/train/img/X00016469622.jpg'\n",
    "#image_path = 'SROIE2019/train/img/X51005361883.jpg' #ä¸€è·‘å°±å´©\n",
    "\n",
    "# Get raw OCR data and save to DataFrame / è·å–è¯†åˆ«åçš„åŸå§‹æ•°æ®å¹¶ä¿å­˜åœ¨ DataFrame\n",
    "df_ocr_result = process1_getdata(image_path)\n",
    "df_ocr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f57fe9a9-3aa8-4318-9cd9-1e0a2f9133ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4: Extracting information... / æ­¥éª¤4ï¼šæå–ä¿¡æ¯...\n",
      "ADDING MARK COLUMN / æ·»åŠ æ ‡è®°åˆ†ç±»:\n",
      "======================================================================\n",
      "ADDING ROW NUMBER COLUMN / æ·»åŠ è¡Œå·:\n",
      "======================================================================\n",
      "ADDING PRIORITY COLUMN / æ·»åŠ æœ‰æ•ˆä¿¡æ¯æƒé‡åˆ—:\n",
      "======================================================================\n",
      "ADDING COLUMN NUMBERS / æ·»åŠ åˆ—å·:\n",
      "======================================================================\n",
      "MARKING UNITS / æ ‡è®°å•ä½:\n",
      "======================================================================\n",
      "UPDATING PRIORITY MARKS / æ›´æ–°ä¼˜å…ˆçº§æ ‡è®°:\n",
      "======================================================================\n",
      "CALCULATING ROW DIFFERENCES / è®¡ç®—è¡Œå·®:\n",
      "======================================================================\n",
      "DELETING ROWS BY ROW_DIFF / æ ¹æ®row_diffåˆ é™¤è¡Œ:\n",
      "======================================================================\n",
      "CREATING MATCHED DATAFRAME / åˆ›å»ºé…å¯¹DataFrame:\n",
      "======================================================================\n",
      "FINAL MATCHED DATAFRAME / æœ€ç»ˆé…å¯¹DataFrame:\n",
      "Total matched pairs: 8\n",
      "======================================================================\n",
      "\n",
      "âœ… Target information extraction completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REPAIR ENGINE POWER SPRAYER (1UNIT)</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GIANT 606 OVERFLOW ASSY</td>\n",
       "      <td>160.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENGINE OIL</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GREASE FOR TOOLS 40ML (AKODA)</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EY20 PLUG CHAMPION</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>STARTER TALI</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EY20 STARTER HANDLE</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HD40 1L COTIN</td>\n",
       "      <td>36.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  item   price\n",
       "0  REPAIR ENGINE POWER SPRAYER (1UNIT)   80.00\n",
       "1              GIANT 606 OVERFLOW ASSY  160.00\n",
       "2                           ENGINE OIL   17.00\n",
       "3        GREASE FOR TOOLS 40ML (AKODA)   10.00\n",
       "4                   EY20 PLUG CHAMPION    6.00\n",
       "5                         STARTER TALI    8.00\n",
       "6                  EY20 STARTER HANDLE   10.00\n",
       "7                        HD40 1L COTIN   36.00"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Process data and extract key info / è¿è¡Œæ­¥éª¤2ï¼šå¤„ç†æ•°æ®ï¼Œæå–å…³é”®ä¿¡æ¯\n",
    "date, df_mark_data, df_valid_data, df_goal_data, df_matched_goal_data = process2_get_main_information(df_ocr_result)\n",
    "df_matched_goal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82565ec9-e407-4f08-89e6-1f5e9e5afc3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "               ğŸ“‹ RECEIPT VIEWER / æ”¶æ®æŸ¥çœ‹å™¨\n",
      "======================================================================\n",
      "\n",
      "ğŸ“… Date / æ—¥æœŸ: Date: 11/01/2019\n",
      "ğŸ†” Receipt ID / æ”¶æ®ç¼–å·: #1\n",
      "ğŸ“¦ Total Items / å•†å“æ€»æ•°: 8\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "                    ğŸ“ ITEMS LIST / å•†å“åˆ—è¡¨\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9506293cda254f0da43ebef3656334e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae16bb65e5b41858d9ebd17327d127e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "                âœï¸  EDIT DATA / ç¼–è¾‘æ•°æ®\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b5ea1e23a04f4cac7b7181eec23808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=1, description='Row / è¡Œå·:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48003901263240ec9a08a849c5abd283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Item / å•†å“:', layout=Layout(width='400px'), placeholder='Item name')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6f7f824b2a494288c01ac526cefeae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Price / ä»·æ ¼:', placeholder='0.00')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31585e0546424fad83ba67fa8f2e75f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='success', description='âœš Add / æ–°å¢', icon='plus', style=ButtonStyle()), Butâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c85657c78d4201b45cde4da50cc4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ“– Instructions / ä½¿ç”¨è¯´æ˜:\n",
      "----------------------------------------------------------------------\n",
      "1. Add / æ–°å¢: Enter item and price, click Add\n",
      "   è¾“å…¥å•†å“åå’Œä»·æ ¼ï¼Œç‚¹å‡»æ–°å¢\n",
      "2. Update / æ›´æ–°: Enter row number and new values, click Update\n",
      "   è¾“å…¥è¡Œå·å’Œæ–°å€¼ï¼Œç‚¹å‡»æ›´æ–°\n",
      "3. Delete / åˆ é™¤: Enter row number, click Delete\n",
      "   è¾“å…¥è¡Œå·ï¼Œç‚¹å‡»åˆ é™¤\n",
      "4. Reset / é‡ç½®: Restore original data\n",
      "   æ¢å¤åŸå§‹æ•°æ®\n",
      "5. Export CSV / å¯¼å‡º: Save to file\n",
      "   ä¿å­˜ä¸ºæ–‡ä»¶\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Visualize results and enable edit/export / è¿è¡Œæ­¥éª¤3ï¼šç»“æœå¯è§†åŒ–å¹¶æä¾›ä¿®æ”¹å¯¼å‡ºåŠŸèƒ½\n",
    "\n",
    "# Convert final data to dictionary / å°†å¾—åˆ°çš„æœ€ç»ˆæ•°æ®è½¬æ¢ä¸ºå­—å…¸ç±»å‹\n",
    "receipt = {\n",
    "    'date': date,\n",
    "    'items': df_matched_goal_data.rename(columns={'item': 'Item', 'price': 'Price'}).to_dict('records')\n",
    "}\n",
    "\n",
    "# Pass data to frontend for display / å°†æ•°æ®ä¼ å…¥å‰ç«¯è¿›è¡Œæ˜¾ç¤º\n",
    "create_interactive_viewer(receipt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbd8677-1b5b-474d-8977-c9e20cc10a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
