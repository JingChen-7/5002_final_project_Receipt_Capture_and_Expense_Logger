{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "487eab53-d302-43f0-9bca-f12ac21862ef",
   "metadata": {},
   "source": [
    "# Usage Instructions\n",
    "1. Place the receipt image in the same folder as the code.\n",
    "2. Enter the image path in the image_path field of the entry point.\n",
    "3. Run all the code cells in order.\n",
    "\n",
    "Note: The first time you run this code, you need to install the required libraries.\n",
    "\n",
    "## Expected Result\n",
    "1. The program will recognize the items and prices from the receipt image.\n",
    "2. A visual interactive viewer will appear.\n",
    "3. You can add, update, delete, or export items using the buttons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "b098b8d17e1d43df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python paddlepaddle paddleocr pillow ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "227dd59d-24fd-4767-8138-74ae1c2ddb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from paddleocr import PaddleOCR\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore') #Ignore all Python warnings\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b93b64-7e85-4786-87fa-ae6c00d98c72",
   "metadata": {},
   "source": [
    "# PART 1: Image Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "8d5214d6-f6cc-48f9-aa96-3c108f9d4705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image from file\n",
    "def load_image(image_path):\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"❌ Error: File not found - {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(\"❌ Error: Cannot read image\")\n",
    "        return None\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Complete image preprocessing pipeline\n",
    "def preprocess_image(image_path):\n",
    "\n",
    "    # Load image\n",
    "    original = load_image(image_path)\n",
    "    if original is None:\n",
    "        return None\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Remove noise\n",
    "    denoised = cv2.fastNlMeansDenoising(gray, None, 10, 7, 21)\n",
    "    \n",
    "    # Apply adaptive thresholding (convert to black & white)\n",
    "    threshold = cv2.adaptiveThreshold(\n",
    "        denoised, 255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY, 11, 2\n",
    "    )\n",
    "    \n",
    "    return threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f21c7de-6502-4510-857b-fa9148a1c226",
   "metadata": {},
   "source": [
    "# PART 2: OCR Recognition Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "c010d951-585d-4a26-9b34-3c32c48c5b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize PaddleOCR engine\n",
    "def initialize_ocr():\n",
    "    ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
    "    return ocr\n",
    "\n",
    "#Perform OCR on image\n",
    "def perform_ocr(ocr, image_path):\n",
    "    \n",
    "    #\"Get all text from OCR\n",
    "    result = ocr.ocr(image_path)\n",
    "    \n",
    "    if result is None or len(result) == 0:\n",
    "        print(\"❌ OCR returned no results!\")\n",
    "        return []\n",
    "    \n",
    "    #Print the OCR result\n",
    "    #print(result)\n",
    "    #print(\"=\"*70 + \"\\n\")\n",
    "    return result[0] if len(result) > 0 else []\n",
    "\n",
    "#Organize OCR results\n",
    "def organize_ocr_results(ocr_result):\n",
    "    df_ocr_result = pd.DataFrame(columns=[\"text\",\"confidence\",\"left_top_x\",\"left_top_y\",\n",
    "                                          \"right_top_x\",\"right_top_y\",\"left_bottom_x\",\n",
    "                                          \"left_bottom_y\",\"right_bottom_x\",\"right_bottom_y\"])\n",
    "    \n",
    "    print(\"Organize OCR data...\")\n",
    "\n",
    "    texts = ocr_result.get('rec_texts', [])\n",
    "    scores = ocr_result.get('rec_scores', [1.0] * len(texts))\n",
    "    polys = ocr_result.get('rec_polys', [])\n",
    "\n",
    "    \n",
    "    for idx, text in enumerate(texts):\n",
    "        confidence = scores[idx] if idx < len(scores) else 1.0   #Use 1.0 when scores and text lengths differ\n",
    "        \n",
    "        # Get coordinates\n",
    "        if idx < len(polys) and len(polys[idx]) >= 4:\n",
    "            poly = polys[idx]\n",
    "        else:\n",
    "            poly = [[0,0],[0,0],[0,0],[0,0]]\n",
    "\n",
    "        # Save text into dataframe\n",
    "        df_ocr_result.loc[len(df_ocr_result.index)] = [str(text),float(confidence),poly[0][0],poly[0][1],\n",
    "                                                       poly[1][0],poly[1][1],poly[2][0],poly[2][1],poly[3][0],\n",
    "                                                       poly[3][1]]\n",
    "    return df_ocr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a309cce1-f9e1-41ca-8205-d9e5ee42e3bf",
   "metadata": {},
   "source": [
    "# PART 3: Information Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "d378c177-8ce3-4c07-993c-26cf0e69f6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These functions must be called in order\n",
    "\n",
    "#Extract date from text\n",
    "def extract_date(text):\n",
    "    \"\"\"\n",
    "    Extract a date from text and return it in MM/DD/YYYY format.\n",
    "    If no date found, return \"0\".\n",
    "    \"\"\"\n",
    "    # Various date matching patterns\n",
    "    patterns = [\n",
    "        r'\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}',        # 25/12/2025 or 12-25-25\n",
    "        r'\\d{4}[-/]\\d{1,2}[-/]\\d{1,2}',          # 2025/12/25\n",
    "        r'\\d{1,2}\\.\\d{1,2}\\.\\d{2,4}',            # 25.12.2025\n",
    "        r'\\d{1,2}\\s+\\w+\\s+\\d{2,4}',              # 25 Dec 2025\n",
    "        r'\\w+\\s+\\d{1,2},?\\s+\\d{2,4}',            # Dec 25, 2025\n",
    "        r'\\d{1,2}(st|nd|rd|th)?\\s+\\w+\\s+\\d{4}',  # 25th December 2025\n",
    "    ]\n",
    "\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            found_date = match.group()\n",
    "\n",
    "            # Try to parse the date and return in MM/DD/YYYY format\n",
    "            for fmt in [\"%d/%m/%Y\", \"%m/%d/%Y\", \"%Y/%m/%d\", \"%d-%m-%Y\", \"%m-%d-%Y\", \"%d.%m.%Y\",\n",
    "                        \"%d %b %Y\", \"%d %B %Y\", \"%b %d, %Y\", \"%B %d, %Y\", \"%d %B %Y\", \"%d %b %Y\"]:\n",
    "                try:\n",
    "                    dt = datetime.strptime(found_date, fmt)\n",
    "                    return dt.strftime(\"%m/%d/%Y\")\n",
    "                except:\n",
    "                    continue\n",
    "            # If matched but cannot be parsed, return the original string\n",
    "            return found_date\n",
    "    # Return \"0\" if no match is found\n",
    "    return 0\n",
    "    \n",
    "#====================================================================================================\n",
    "def classify_text_type(text):\n",
    "    \"\"\"\n",
    "    Classify text type\n",
    "    \n",
    "    Returns:\n",
    "    - 'price' : Price (two decimal places)\n",
    "    - 'code' : Code (long digit string or alphanumeric)\n",
    "    - 'header' : Header keyword (PRICE, QTY, AMOUNT, etc.)\n",
    "    - 'payment' : Payment keyword (TOTAL, CASH, CHANGE, etc.)\n",
    "    - 'invalid': All symbols or over 80% symbols\n",
    "    - 'text' : Regular text\n",
    "\n",
    "    \"\"\"  \n",
    "    \n",
    "    text_clean = text.strip()\n",
    "    text_lower = text_clean.lower()\n",
    "\n",
    "\n",
    "    # 1. Check for date type\n",
    "    if extract_date(text) != 0:\n",
    "        return 'date'\n",
    "    \n",
    "    \n",
    "    # 2. Check for header keywords\n",
    "    header_keywords = ['price', 'amount', 'qty', 'quantity', 'item', \n",
    "                      'description', 'product', 'code', 'desc']\n",
    "    \n",
    "    if any(kw == text_lower or kw in text_lower for kw in header_keywords):\n",
    "        if len(text_clean) < 20:  # Header keywords are usually short\n",
    "            return 'header'\n",
    "    \n",
    "    # 3. Check for payment keywords\n",
    "    payment_keywords = ['total', 'subtotal', 'grand total', \n",
    "                       'cash', 'payment', 'paid',\n",
    "                       'change', 'balance',\n",
    "                       'tax', 'vat', 'gst',\n",
    "                       'discount', 'promo']\n",
    "    \n",
    "    if any(kw in text_lower for kw in payment_keywords):\n",
    "        return 'payment'\n",
    "    \n",
    "    # 4. Check if it's a price (number with 2 decimals)\n",
    "    # Pattern: $12.50 or 12.50 or 12.50$\n",
    "    price_pattern = r'^\\$?\\s*\\d+[.,]\\d{2}\\s*\\$?$'\n",
    "    if re.match(price_pattern, text_clean):\n",
    "        return 'price'\n",
    "    \n",
    "    # 5. Check if it is a product code\n",
    "    text_no_space = text_clean.replace(' ', '').replace('-', '').replace('.', '')\n",
    "    \n",
    "    if len(text_no_space) > 0:\n",
    "        # Rule 1: Pure digits with length > 3 (4 or more digits)\n",
    "        if text_no_space.isdigit() and len(text_no_space) > 3:\n",
    "            return 'code'\n",
    "        \n",
    "        # Rule 2: Digit ratio > 70% \n",
    "        # Also require minimum length > 3 to avoid short mixed text\n",
    "        digit_count = sum(c.isdigit() for c in text_no_space)\n",
    "        total_length = len(text_no_space)\n",
    "        digit_ratio = digit_count / total_length\n",
    "        \n",
    "        if digit_ratio > 0.7 and total_length > 3:\n",
    "            return 'code'\n",
    "\n",
    "     # 6. Check for symbols\n",
    "    if len(text_no_space) > 0:\n",
    "        # Remove all letters and digits\n",
    "        text_no_alnum = re.sub(r'[a-zA-Z0-9]', '', text_no_space)\n",
    "        \n",
    "        # Calculate symbol ratio\n",
    "        symbol_ratio = len(text_no_alnum) / len(text_no_space)\n",
    "        \n",
    "        # If 80% or more are symbols, mark as invalid\n",
    "        if symbol_ratio >= 0.8:\n",
    "            return 'invalid'\n",
    "        # If less than 4 characters, mark as invalid\n",
    "        if len(text_no_space) < 4:\n",
    "            return 'invalid'\n",
    "\n",
    "    \n",
    "    # 7. Otherwise it's text\n",
    "    return 'text'\n",
    "\n",
    "#====================================================================================================\n",
    "def add_row_number(df):\n",
    "    # Add row_No column\n",
    "    print(\"\\nStep 5: Add row number column...\")\n",
    "    \n",
    "    row_no = 1  # Start from row 1\n",
    "    df.loc[0, 'row_No'] = row_no  # First element corresponds to row 1\n",
    "    \n",
    "    # Iterate through each row and check if it's a new row\n",
    "    for i in range(1, len(df)):\n",
    "        # Current row's center_y\n",
    "        current_y = df.loc[i, 'left_bottom_y']\n",
    "        \n",
    "        # Previous row's center_y\n",
    "        previous_y = df.loc[i-1, 'left_bottom_y']\n",
    "        \n",
    "        # Calculate the difference\n",
    "        diff = abs(current_y - previous_y)\n",
    "        \n",
    "        # If difference < 20, consider same row; otherwise, assign a new row_No\n",
    "        if diff < 20:\n",
    "            df.loc[i, 'row_No'] = row_no\n",
    "        else:\n",
    "            row_no += 1  # For a new row, increment row_No by 1\n",
    "            df.loc[i, 'row_No'] = row_no\n",
    "    \n",
    "    # Convert to integer type\n",
    "    df['row_No'] = df['row_No'].astype(int)\n",
    "    return df\n",
    "\n",
    "#====================================================================================================\n",
    "def add_priority_column(df):\n",
    "    \"\"\"\n",
    "    Higher priority means closer to target content\n",
    "    \n",
    "    Rule:\n",
    "    - Find first row where mark='header' → row_head\n",
    "    - Find first row where text contains 'total' → row_tail\n",
    "    - Rows where row_head <= row_No < row_tail → mark as 1\n",
    "    - Other rows → mark as 0\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\nStep 6: Add priority column...\")\n",
    "    \n",
    "    # Initialize priority to 0 \n",
    "    df['priority'] = 0\n",
    "    \n",
    "    # Find row_head (first header row)\n",
    "    header_rows = df[df['mark'] == 'header']\n",
    "    \n",
    "    if len(header_rows) > 0:\n",
    "        row_head = header_rows['row_No'].min()\n",
    "    else:\n",
    "        print(\"❌ No header found, using row_No 0 as row_head\")\n",
    "        row_head = 0\n",
    "    \n",
    "    # Find row_tail (first row with 'total' in text)\n",
    "    total_rows = df[df['text'].str.lower().str.contains('total', na=False)]\n",
    "    \n",
    "    if len(total_rows) > 0:\n",
    "        row_tail = total_rows['row_No'].min()\n",
    "    else:\n",
    "        print(\"❌ No 'total' found, using last row as row_tail\")\n",
    "        row_tail = df['row_No'].max() + 1\n",
    "    \n",
    "    # Set priority to 1 for rows between header and total\n",
    "    # Rows where row_head <= row_No < row_tail → mark as 1\n",
    "    # Other rows → mark as 0\n",
    "    df['priority'] = ((df['row_No'] >= row_head) & (df['row_No'] < row_tail)).astype(int)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "#====================================================================================================    \n",
    "def add_column_number(df):\n",
    "    \"\"\"\n",
    "    Add 'col_No' column based on x position.\n",
    "    Rule: If horizontal overlap ratio > 70%, consider as same column.\n",
    "    \"\"\"\n",
    "    print(\"\\nStep 7: Add column number column...\")\n",
    "    # Sort by x (left to right), then y (top to bottom)\n",
    "    df_sorted = df.sort_values(['left_top_x', 'left_top_y']).reset_index()\n",
    "\n",
    "    df_sorted['col_No'] = 0\n",
    "    curr_col_No = 1\n",
    "    # Initialize current column x-range\n",
    "    curr_min_x = df_sorted.loc[0, 'left_top_x']\n",
    "    curr_max_x = df_sorted.loc[0, 'right_top_x']\n",
    "\n",
    "    for idx, row in df_sorted.iterrows():\n",
    "        left_x = row['left_top_x']\n",
    "        right_x = row['right_top_x']\n",
    "        width = right_x - left_x\n",
    "\n",
    "        # Compute intersection with current column\n",
    "        intersect_len = max(0, min(curr_max_x, right_x) - max(curr_min_x, left_x))\n",
    "        overlap_ratio = max(intersect_len / width, intersect_len / (curr_max_x - curr_min_x))\n",
    "\n",
    "        if overlap_ratio < 0.7:\n",
    "            # Not enough overlap → new column\n",
    "            curr_col_No += 1\n",
    "            curr_min_x = left_x\n",
    "            curr_max_x = right_x\n",
    "        else:\n",
    "            # Update current column range\n",
    "            curr_min_x = min(curr_min_x, left_x)\n",
    "            curr_max_x = max(curr_max_x, right_x)\n",
    "\n",
    "        df_sorted.at[idx, 'col_No'] = curr_col_No\n",
    "\n",
    "    # Restore original df order\n",
    "    df_sorted = df_sorted.sort_values('index').drop(columns='index')\n",
    "    df_sorted['col_No'] = df_sorted['col_No'].astype(int)\n",
    "\n",
    "    return df_sorted\n",
    "\n",
    "#====================================================================================================\n",
    "# Update category text type: mark as \"Unit\"\n",
    "def mark_units(df):\n",
    "    \"\"\"\n",
    "    Mark units directly in the 'mark' column\n",
    "\n",
    "    Rules::\n",
    "    1. Directly matches common unit labels\n",
    "    2. Number followed by common unit labels\n",
    "    3. Pure number in the same column as header \"Qty\"\n",
    "    \"\"\"\n",
    "    print(\"\\nStep 8: Mark units...\")\n",
    "    \n",
    "    # Common units\n",
    "    unit_keywords = [\n",
    "        # Counting\n",
    "        'PC', 'PCS', 'PIECE', 'PIECES', 'EA', 'EACH', 'UNIT',\n",
    "        \n",
    "        # Weight\n",
    "        'KG', 'G', 'GM', 'GRAM', 'LB', 'POUND', 'OZ', 'OUNCE',\n",
    "        \n",
    "        # Volume\n",
    "        'L', 'ML', 'LITER', 'GAL', 'GALLON', 'FL OZ',\n",
    "        \n",
    "        # Packaging\n",
    "        'BOX', 'BAG', 'BTL', 'BOTTLE', 'CAN', 'PKT', 'PACKET',\n",
    "        'CTN', 'CARTON', 'JAR', 'TIN', 'TUBE',\n",
    "        \n",
    "        # Other\n",
    "        'PAIR', 'SET', 'ROLL', 'PACK', 'BUNCH', 'DOZEN', 'DZ']\n",
    "    \n",
    "    # Find Qty column if exists\n",
    "    qty_headers = df[(df['mark'] == 'header') & \n",
    "                    (df['text'].str.upper().str.contains('QTY|QUANTITY', na=False))]\n",
    "    \n",
    "    qty_col = None\n",
    "    if len(qty_headers) > 0:\n",
    "        qty_col = qty_headers.iloc[0]['col_No']    \n",
    "    \n",
    "    # Check each row\n",
    "    for idx in df.index:\n",
    "        text = df.loc[idx, 'text']\n",
    "        text_upper = text.upper().strip()\n",
    "        \n",
    "        is_unit = False\n",
    "        \n",
    "        # Rule 1: Keyword match\n",
    "        if text_upper in unit_keywords:\n",
    "            is_unit = True\n",
    "        \n",
    "        # Rule 2: Pattern match (e.g., \"1 PC\")\n",
    "        if not is_unit:\n",
    "            pattern = r'^\\d+\\.?\\d*\\s*(' + '|'.join(unit_keywords) + r')$'\n",
    "            if re.match(pattern, text_upper):\n",
    "                is_unit = True\n",
    "        \n",
    "        # Rule 3: Pure number in Qty column\n",
    "        if not is_unit and qty_col is not None:\n",
    "            current_col = df.loc[idx, 'col_No']\n",
    "            \n",
    "            if current_col == qty_col:\n",
    "                text_clean = text.replace('.', '').replace(',', '')\n",
    "                if text_clean.isdigit():\n",
    "                    try:\n",
    "                        num = float(text)\n",
    "                        if 0 < num < 1000:\n",
    "                            is_unit = True\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        # Update mark to 'unit' if identified\n",
    "        if is_unit:\n",
    "            df.loc[idx, 'mark'] = 'unit'\n",
    "            \n",
    "    return df\n",
    "\n",
    "#====================================================================================================\n",
    "# Update priority (mark as 2)\n",
    "def update_priority_marks(df):\n",
    "    \"\"\"\n",
    "    Update priority marks with additional rules\n",
    "\n",
    "    Rules:\n",
    "    1. If code and text are in same row or adjacent rows in same column，increase text's priority to 2\n",
    "    1: If a code and text are adjacent in the same row or column, increase text's priority to 2\n",
    "    3. If text is in same column as 'item' header，increase text's priority to 2\n",
    "    \"\"\"\n",
    "    print(\"\\nStep 9: Update priority marks...\")\n",
    "    \n",
    "    # Keywords that indicate summary/total amounts\n",
    "    total_keywords = [\n",
    "        'amount', 'sum', 'balance', 'due', 'payable', 'net', 'gross']\n",
    "    \n",
    "    # Rule 1: Code + Text in same/adjacent rows in same column\n",
    "    for idx, row in df.iterrows():\n",
    "        if row['mark'] == 'text' and row['priority'] == 1:\n",
    "            text_row = row['row_No']\n",
    "            text_col = row['col_No']\n",
    "            \n",
    "            for idx2, row2 in df.iterrows():\n",
    "                if row2['mark'] == 'code':\n",
    "                    code_row = row2['row_No']\n",
    "                    code_col = row2['col_No']\n",
    "                    \n",
    "                    same_row = (text_row == code_row)\n",
    "                    same_col = (text_col == code_col)\n",
    "                    adjacent_row = abs(text_row - code_row) == 1\n",
    "                    \n",
    "                    if same_row or (same_col and adjacent_row):\n",
    "                        df.loc[idx, 'priority'] = 2\n",
    "                        break\n",
    "    \n",
    "    # Rule 2: Price + Total keywords\n",
    "    for idx, row in df.iterrows():\n",
    "        if row['mark'] == 'price':\n",
    "            price_col = row['col_No']\n",
    "            price_row = row['row_No']\n",
    "            \n",
    "            for idx2, row2 in df.iterrows():\n",
    "                text_lower = row2['text'].lower()\n",
    "                \n",
    "                contains_keyword = any(kw in text_lower for kw in total_keywords)\n",
    "                \n",
    "                if contains_keyword and row2['col_No'] == price_col:            \n",
    "                    df.loc[idx, 'priority'] = 2\n",
    "                    break\n",
    "    \n",
    "    # Rule 3: Text in same column as 'item' header\n",
    "    # Find 'item' header column\n",
    "    item_headers = df[(df['mark'] == 'header') & \n",
    "                     (df['text'].str.upper().str.contains('ITEM|DESCRIPTION|DESC|PRODUCT|NAME', na=False))]\n",
    "    \n",
    "    if len(item_headers) > 0:\n",
    "        item_col = item_headers.iloc[0]['col_No']\n",
    "        \n",
    "        # Mark all text items in this column as priority=2\n",
    "        for idx, row in df.iterrows():\n",
    "            if row['mark'] == 'text' and row['col_No'] == item_col and row['priority'] == 1:\n",
    "                df.loc[idx, 'priority'] = 2      \n",
    "                text_row = row['row_No']\n",
    "    else:\n",
    "        print(\"❌No 'item' header found\")\n",
    "        \n",
    "    return df\n",
    "\n",
    "#====================================================================================================\n",
    "def calculate_row_diff(df):\n",
    "    \"\"\"\n",
    "    Calculate row difference between \"price\" and \"text\"\n",
    "    Used to match extracted items with their corresponding amounts\n",
    "    \n",
    "    Logic:\n",
    "    1. Count the number of \"price\" and \"text\" entries to find unmatched extra rows\n",
    "    2. For the type with more entries, calculate row difference to nearest row of the other type\n",
    "    3. Store row differences in row_diff column\n",
    "    \"\"\"\n",
    "    print(\"\\nStep 10: Calculate row differences...\")\n",
    "    \n",
    "    # Filter priority=2 and mark in ['text', 'price'] \n",
    "    filtered = df[(df['priority'] == 2) & \n",
    "                  (df['mark'].isin(['text', 'price']))]\n",
    "    \n",
    "    # Count text and price\n",
    "    text_count = len(filtered[filtered['mark'] == 'text'])\n",
    "    price_count = len(filtered[filtered['mark'] == 'price'])\n",
    "    \n",
    "    # Initialize row_diff column\n",
    "    filtered['row_diff'] = None\n",
    "    \n",
    "    # # Count of extra rows that need to be deleted\n",
    "    delete_rows_count = 0\n",
    "\n",
    "    # Compare row counts of price and text to set up data for deleting useless rows later\n",
    "    # If the row count of price is greater: use the row of each price to identify the corresponding text with the nearest row\n",
    "    if price_count > text_count:     \n",
    "        search_type = 'price'\n",
    "        target_type = 'text'\n",
    "        delete_rows_count = price_count - text_count\n",
    "        \n",
    "    # If the row count of text is greater: use the row of each text to identify the corresponding price with the nearest row\n",
    "    elif text_count > price_count:      \n",
    "        search_type = 'text'\n",
    "        target_type = 'price'\n",
    "        delete_rows_count = text_count - price_count\n",
    "    \n",
    "    # Equal count, defaulting to use the row of each price to identify the corresponding text with the nearest row\n",
    "    else:\n",
    "        search_type = 'price'\n",
    "        target_type = 'text'\n",
    "\n",
    "    \n",
    "    for idx in filtered.index:\n",
    "        # Check if this is the search type\n",
    "        if filtered.loc[idx, 'priority'] == 2 and filtered.loc[idx, 'mark'] == search_type:\n",
    "            current_row = filtered.loc[idx, 'row_No']\n",
    "            #current_text = filtered.loc[idx, 'text']\n",
    "            \n",
    "            # Find nearest target type\n",
    "            min_diff = float('inf')\n",
    "            nearest_target = None\n",
    "            \n",
    "            for idx2 in filtered.index:\n",
    "                if filtered.loc[idx2, 'priority'] == 2 and filtered.loc[idx2, 'mark'] == target_type:\n",
    "                    target_row = filtered.loc[idx2, 'row_No']\n",
    "                    diff = abs(target_row - current_row)\n",
    "                    \n",
    "                    # Update if closer\n",
    "                    if diff < min_diff:\n",
    "                        min_diff = diff\n",
    "                        nearest_target = {\n",
    "                            'idx': idx2,\n",
    "                            'row': target_row,\n",
    "                            'text': filtered.loc[idx2, 'text']\n",
    "                        }\n",
    "            \n",
    "            # Store the difference\n",
    "            if nearest_target:\n",
    "                # Calculate difference\n",
    "                actual_diff = nearest_target['row'] - current_row\n",
    "                filtered.loc[idx, 'row_diff'] = actual_diff\n",
    "            else:\n",
    "                filtered.loc[idx, 'row_diff'] = None\n",
    "    return filtered, delete_rows_count\n",
    "    \n",
    "#====================================================================================================\n",
    "def delete_by_row_diff(df, delete_rows_count):\n",
    "    \"\"\"\n",
    "    Delete extra rows based on row_diff distribution\n",
    "    \n",
    "    Logic:\n",
    "    1. Count row_diff value distribution\n",
    "    2. Delete rows with least frequent and largest absolute difference\n",
    "    3. Repeat until deleted delete_rows_count rows\n",
    "    \"\"\"\n",
    "    print(\"\\nStep 11: Delete rows based on row_diff...\")\n",
    "    \n",
    "    # Get rows that have row_diff\n",
    "    rows_with_diff = df[df['row_diff'].notna()].copy()\n",
    "    \n",
    "    if len(rows_with_diff) == 0:\n",
    "        print(\"❌ No rows with row_diff to delete\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "        return df\n",
    "        \n",
    "    # Track deleted indices\n",
    "    to_delete_indices = []\n",
    "    deleted_count = 0\n",
    "    \n",
    "    # Loop until we've deleted enough rows\n",
    "    while deleted_count < delete_rows_count:\n",
    "        # Get current row_diff distribution (excluding already marked for deletion)\n",
    "        remaining = rows_with_diff[~rows_with_diff.index.isin(to_delete_indices)]\n",
    "        \n",
    "        if len(remaining) == 0:\n",
    "            print(f\"\\n❌ No more rows to delete (deleted {deleted_count}/{delete_rows_count})\")\n",
    "            break\n",
    "        \n",
    "        # Count distribution\n",
    "        diff_counts = remaining['row_diff'].value_counts()\n",
    "        \n",
    "        # Find minimum count\n",
    "        min_count = diff_counts.min()\n",
    "\n",
    "        # Get all row_diff values with minimum count\n",
    "        min_count_diffs = diff_counts[diff_counts == min_count].index.tolist()\n",
    "       \n",
    "        # Among these, find the one with largest absolute value\n",
    "        max_abs_diff = max(min_count_diffs, key=abs)\n",
    "        \n",
    "        # Get rows with this row_diff value\n",
    "        rows_to_delete = remaining[remaining['row_diff'] == max_abs_diff]\n",
    "\n",
    "        # Delete these rows (or as many as needed)\n",
    "        for idx in rows_to_delete.index:\n",
    "            if deleted_count >= delete_rows_count:\n",
    "                break\n",
    "            \n",
    "            to_delete_indices.append(idx)\n",
    "            deleted_count += 1\n",
    "    \n",
    "    # Actually delete from DataFrame\n",
    "    df = df.drop(to_delete_indices).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "#====================================================================================================\n",
    "def create_matched_dataframe(df):\n",
    "    \"\"\"\n",
    "    Create final DataFrame with matched items and prices\n",
    "    Add row_match column; rows with the same row_match form a pair\n",
    "    \n",
    "    Columns: item, price\n",
    "    \"\"\"\n",
    "    print(\"\\nStep 12: Create matched DataFrame...\")\n",
    "\n",
    "    # Add row_match column\n",
    "    # If row_diff is None, use row_No directly; otherwise, use row_No + row_diff\n",
    "    df['row_match'] = df.apply(lambda row: row['row_No'] if pd.isna(row['row_diff']) \n",
    "                                                        else row['row_No'] + row['row_diff'], axis=1).astype(int)\n",
    "    \n",
    "    # Get unique row_match values\n",
    "    unique_matches = df['row_match'].unique()\n",
    "    unique_matches = sorted(unique_matches)\n",
    "    \n",
    "    # Store matched pairs\n",
    "    matched_list = []\n",
    "    \n",
    "    # Process each row_match value\n",
    "    for match_value in unique_matches:\n",
    "        # Get all rows with this row_match\n",
    "        matched_rows = df[df['row_match'] == match_value]\n",
    "        \n",
    "        # Find text and price\n",
    "        texts = matched_rows[matched_rows['mark'] == 'text']\n",
    "        prices = matched_rows[matched_rows['mark'] == 'price']\n",
    "        \n",
    "        # Only add if both text and price exist\n",
    "        if len(texts) > 0 and len(prices) > 0:\n",
    "            # Get first text and first price\n",
    "            item_text = texts.iloc[0]['text']\n",
    "            price_text = prices.iloc[0]['text']\n",
    "            \n",
    "            # Add to list\n",
    "            matched_list.append({\n",
    "                'item': item_text,\n",
    "                'price': price_text\n",
    "            })\n",
    "        else:\n",
    "            if len(texts) == 0:\n",
    "                print(f\"No text found\")\n",
    "            elif len(prices) == 0:\n",
    "                print(f\"No price found (has text: '{texts.iloc[0]['text']}')\")\n",
    "    \n",
    "    # Create final DataFrame\n",
    "    final_df = pd.DataFrame(matched_list)\n",
    "    \n",
    "    print(\"Final matched DataFrame:\")\n",
    "    print(f\"Total matched pairs: {len(final_df)}\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4235d009-179d-4c23-9165-f1f23060b557",
   "metadata": {},
   "source": [
    "# PART 4: Interactive Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "75af08f1-dd35-45c1-9cb9-422ea3462908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count letters\n",
    "def count_letters(text):\n",
    "    if text is None:\n",
    "        return 0\n",
    "    c = 0\n",
    "    for ch in str(text):\n",
    "        if ('a' <= ch <= 'z') or ('A' <= ch <= 'Z'):\n",
    "            c += 1\n",
    "    return c\n",
    "\n",
    "# Price validation: numeric or decimal (up to two decimal places)\n",
    "def validate_price(price_text):\n",
    "    if price_text is None:\n",
    "        return False, None\n",
    "    s = str(price_text).strip()\n",
    "    if s == \"\":\n",
    "        return False, None\n",
    "    if re.match(r'^\\d+(\\.\\d{1,2})?$', s):\n",
    "        try:\n",
    "            return True, float(s)\n",
    "        except:\n",
    "            return False, None\n",
    "    return False, None\n",
    "\n",
    "#====================================================================================================\n",
    "# Main function for interactive page\n",
    "def create_interactive_viewer(receipt):\n",
    "    \"\"\"\n",
    "    - receipt: dict, keys: 'date' (optional), 'items' (list of dicts with 'Item' and 'Price')\n",
    "    \"\"\"\n",
    "    # Import data\n",
    "    items = receipt.get(\"items\", []) or []\n",
    "    date = receipt.get(\"date\", \"Unknown\")\n",
    "    \n",
    "    if len(items) == 0:\n",
    "        df = pd.DataFrame(columns=[\"Item\", \"Price\"])\n",
    "        print(\"⚠️ No items detected, showing empty template\")\n",
    "    else:\n",
    "        # Only these two columns\n",
    "        temp = pd.DataFrame(items)\n",
    "        for col in [\"Item\",\"Price\"]:\n",
    "            if col not in temp.columns:\n",
    "                temp[col] = \"\"\n",
    "        df = temp[[\"Item\",\"Price\"]].copy()\n",
    "    \n",
    "    # Deep copy the original data for reset (to prevent later modifications from affecting the original)\n",
    "    original_df = df.copy(deep=True)\n",
    "    \n",
    "    # Receipt ID counter (by date)\n",
    "    if not hasattr(create_interactive_viewer, \"counter\"):\n",
    "        create_interactive_viewer.counter = {}\n",
    "    if date not in create_interactive_viewer.counter:\n",
    "        create_interactive_viewer.counter[date] = 0\n",
    "    create_interactive_viewer.counter[date] += 1\n",
    "    receipt_id = create_interactive_viewer.counter[date]\n",
    "    \n",
    "    # UI\n",
    "    table_output = widgets.Output()\n",
    "    total_output = widgets.Output()\n",
    "    status_output = widgets.Output()\n",
    "    \n",
    "    row_input = widgets.IntText(value=1, description='Row:', min=1)\n",
    "    item_input = widgets.Text(description='Item:', placeholder='Item name (max 30 letters)')\n",
    "    price_input = widgets.Text(description='Price:', placeholder='e.g. 12.50')\n",
    "    \n",
    "    add_btn = widgets.Button(description='Add', button_style='success')\n",
    "    update_btn = widgets.Button(description='Update', button_style='info')\n",
    "    delete_btn = widgets.Button(description='Delete', button_style='danger')\n",
    "    reset_btn = widgets.Button(description='Reset', button_style='warning')\n",
    "    export_btn = widgets.Button(description='Export CSV', button_style='primary')\n",
    "    \n",
    "    # Calculate total price\n",
    "    def calculate_total(df_now):\n",
    "        total = 0.0\n",
    "        for i, row in df_now.iterrows():\n",
    "            ok, v = validate_price(str(row[\"Price\"]).strip())\n",
    "            if ok:\n",
    "                total += v\n",
    "        return total\n",
    "    \n",
    "    # Refresh table display\n",
    "    def refresh_table():\n",
    "        with table_output:\n",
    "            clear_output()\n",
    "            tmp = df.copy()\n",
    "            tmp.index = range(1, len(tmp) + 1)\n",
    "            display(tmp)\n",
    "    # Refresh total price display\n",
    "    def refresh_total():\n",
    "        with total_output:\n",
    "            clear_output()\n",
    "            total = calculate_total(df)\n",
    "            print(\"TOTAL: $%.2f\" % total)\n",
    "    \n",
    "    # Initially display header information\n",
    "    print(\"\\n============================\")\n",
    "    print(\"RECEIPT VIEWER\")\n",
    "    print(\"============================\")\n",
    "    print(\"Date       :\", date)\n",
    "    print(\"Receipt ID :\", receipt_id)\n",
    "    print(\"Items      :\", len(df))\n",
    "    print(\"============================\\n\")\n",
    "\n",
    "    # Refresh the table and total display  \n",
    "    refresh_table()\n",
    "    display(table_output)\n",
    "    refresh_total()\n",
    "    display(total_output)\n",
    "\n",
    "    #========================================================\n",
    "    # Button function  \n",
    "    def on_add(btn):\n",
    "        with status_output:\n",
    "            clear_output()\n",
    "            item = item_input.value or \"\"\n",
    "            price = price_input.value or \"\"\n",
    "            \n",
    "            if item.strip() == \"\":\n",
    "                print(\"❌ Please enter an Item.\")\n",
    "                return\n",
    "            if price.strip() == \"\":\n",
    "                print(\"❌ Please enter a Price.\")\n",
    "                return\n",
    "            \n",
    "            letters = count_letters(item)\n",
    "            if letters > 30:\n",
    "                print(\"❌ Item has %d letters. Maximum allowed is 30.\" % letters)\n",
    "                return\n",
    "            \n",
    "            ok, val = validate_price(price)\n",
    "            if not ok:\n",
    "                print(\"❌ Invalid price format. Use digits or decimal like '12' or '12.50'.\")\n",
    "                return\n",
    "            \n",
    "            # Add new row\n",
    "            df.loc[len(df)] = [item.strip(), \"%.2f\" % val]\n",
    "            # Update row_input maximum\n",
    "            row_input.max = max(1, len(df))\n",
    "\n",
    "            # Refresh the table and total display  \n",
    "            refresh_table()\n",
    "            refresh_total()\n",
    "            print(\"✅ Item added.\")\n",
    "            # Clear input\n",
    "            item_input.value = \"\"\n",
    "            price_input.value = \"\"\n",
    "    \n",
    "    def on_update(btn):\n",
    "        with status_output:\n",
    "            clear_output()\n",
    "            idx = row_input.value - 1\n",
    "            if idx < 0 or idx >= len(df):\n",
    "                print(\"❌ Invalid row number.\")\n",
    "                return\n",
    "            \n",
    "            new_item = item_input.value or \"\"\n",
    "            new_price = price_input.value or \"\"\n",
    "            \n",
    "            # If input is not empty, validate and update; otherwise keep original value\n",
    "            if new_item.strip() != \"\":\n",
    "                letters = count_letters(new_item)\n",
    "                if letters > 30:\n",
    "                    print(\"❌ Item has %d letters. Maximum allowed is 30.\" % letters)\n",
    "                    return\n",
    "                df.at[idx, \"Item\"] = new_item.strip()\n",
    "            \n",
    "            if new_price.strip() != \"\":\n",
    "                ok, val = validate_price(new_price)\n",
    "                if not ok:\n",
    "                    print(\"❌ Invalid price format.\")\n",
    "                    return\n",
    "                df.at[idx, \"Price\"] = \"%.2f\" % val\n",
    "\n",
    "            # Refresh the table and total display  \n",
    "            refresh_table()\n",
    "            refresh_total()\n",
    "            print(\"✅ Row updated.\")\n",
    "            item_input.value = \"\"\n",
    "            price_input.value = \"\"\n",
    "    \n",
    "    def on_delete(btn):\n",
    "        with status_output:\n",
    "            clear_output()\n",
    "            idx = row_input.value - 1\n",
    "            if idx < 0 or idx >= len(df):\n",
    "                print(\"❌ Invalid row number.\")\n",
    "                return\n",
    "            # Delete in place and reset index\n",
    "            df.drop(idx, inplace=True)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "            row_input.max = max(1, len(df))\n",
    "            if row_input.value > row_input.max:\n",
    "                row_input.value = row_input.max\n",
    "\n",
    "            # Refresh the table and total display  \n",
    "            refresh_table()\n",
    "            refresh_total()\n",
    "            print(\"✅ Row deleted.\")\n",
    "    \n",
    "    def on_reset(btn):\n",
    "        nonlocal df  # Use the outer df variable to allow rebinding, preventing crashes when resetting after export\n",
    "        with status_output:\n",
    "            clear_output()\n",
    "            \n",
    "            # Restore df to the original snapshot (deep copy to avoid shared references)\n",
    "            df = original_df.copy(deep=True).reset_index(drop=True)\n",
    "\n",
    "            # Update row_input maximum value and adjust current value if needed\n",
    "            row_input.max = max(1, len(df))\n",
    "            if row_input.value > row_input.max:\n",
    "                row_input.value = row_input.max\n",
    "\n",
    "            # Refresh the table and total display    \n",
    "            refresh_table()\n",
    "            refresh_total()\n",
    "            print(\"✅ Data reset.\")\n",
    "    \n",
    "    def on_export(btn):\n",
    "        # When exporting, do not rebind df; just read and write to file\n",
    "        with status_output:\n",
    "            clear_output()\n",
    "            total = calculate_total(df)\n",
    "            out = []\n",
    "            for i, row in df.iterrows():\n",
    "                price_s = str(row[\"Price\"]).strip()\n",
    "                ok, val = validate_price(price_s)\n",
    "                if not ok:\n",
    "                    val = 0.0\n",
    "                out.append({\n",
    "                    \"Date\": date,\n",
    "                    \"ID\": receipt_id,\n",
    "                    \"Item\": row[\"Item\"],\n",
    "                    \"Cost\": \"%.2f\" % val,\n",
    "                    \"Total\": \"%.2f\" % total\n",
    "                })\n",
    "            out_df = pd.DataFrame(out)\n",
    "            fname = \"receipt_%s_id%s.csv\" % (date.replace(\"/\", \"-\"), receipt_id)\n",
    "            out_df.to_csv(fname, index=False)\n",
    "            print(\"✅ Exported:\", fname)\n",
    "    \n",
    "    # Connect button\n",
    "    add_btn.on_click(on_add)\n",
    "    update_btn.on_click(on_update)\n",
    "    delete_btn.on_click(on_delete)\n",
    "    reset_btn.on_click(on_reset)\n",
    "    export_btn.on_click(on_export)\n",
    "    \n",
    "    # Display widget\n",
    "    display(row_input)\n",
    "    display(item_input)\n",
    "    display(price_input)\n",
    "    display(widgets.HBox([add_btn, update_btn, delete_btn, reset_btn, export_btn]))\n",
    "    display(status_output)\n",
    "    \n",
    "    print(\"\\nInstructions:\")\n",
    "    print(\"1) Add: both Item and Price required.\")\n",
    "    print(\"2) Update: leave a field empty to keep original.\")\n",
    "    print(\"3) Price format: digits or decimal, e.g. 12 or 12.50\")\n",
    "    print(\"4) Item: non-empty and max 30 letters.\")\n",
    "    print(\"========================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193cd67b-a8bb-4397-84a2-c141d3841250",
   "metadata": {},
   "source": [
    "# PART 5: Main Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "cbc554af-d55b-48ac-8277-9148296c64e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process 1: Get data – Image preprocessing and OCR recognition\n",
    "def process1_getdata(image_path):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"Processing: {os.path.basename(image_path)}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Preprocess\n",
    "    print(\"Process 1: Get data...\")\n",
    "    print(\"Step 1: Preprocessing...\")\n",
    "    preprocessed = preprocess_image(image_path)\n",
    "    if preprocessed is None:\n",
    "        print(\"❌ Preprocessing failed!\")\n",
    "        return None\n",
    "    print(\"✅ Preprocessing done\")\n",
    "    \n",
    "    # OCR\n",
    "    print(\"\\nStep 2: OCR Recognition...\")\n",
    "    ocr = initialize_ocr()\n",
    "    ocr_result = perform_ocr(ocr, image_path)\n",
    "\n",
    "    if len(ocr_result) == 0:\n",
    "        print(\"❌ No text detected!\")\n",
    "        return None\n",
    "    print(f\"✅ Detected {len(ocr_result)} text regions\")\n",
    "\n",
    "    # Organize\n",
    "    print(\"\\nStep 3: Organizing data...\")\n",
    "    df_ocr_result = organize_ocr_results(ocr_result)\n",
    "    print(\"✅ Data organized\")\n",
    "    return df_ocr_result\n",
    "\n",
    "# Process 2: Extracting information\n",
    "def process2_get_main_information(df_ocr_result):     \n",
    "    print(\"=\"*70)  \n",
    "    print(\"Process 2: Extracting information...\")\n",
    "    print(\"Step 4: Add mark column...\")\n",
    "\n",
    "    # Roughly label text categories\n",
    "    df_ocr_result['mark'] = df_ocr_result['text'].apply(classify_text_type)\n",
    "\n",
    "    # Get date\n",
    "    date_rows = df_ocr_result[df_ocr_result['mark'] == 'date']\n",
    "    if len(date_rows) > 0:\n",
    "        date_str = date_rows['text'].iloc[0]\n",
    "        date_str = extract_date(date_str)\n",
    "    else:\n",
    "        date_str = datetime.now().strftime(\"%m/%d/%Y\")\n",
    "    \n",
    "    # Add row number\n",
    "    df_mark_data =  add_row_number(df_ocr_result)\n",
    "\n",
    "    # Identify valid table content and set priority to 1\n",
    "    df_mark_data = add_priority_column(df_mark_data)\n",
    "    df_valid_data = df_ocr_result[df_mark_data['priority'] == 1].copy()\n",
    "\n",
    "    # Add column number\n",
    "    df_valid_data = add_column_number(df_valid_data)\n",
    "\n",
    "    # Identify text labeled as \"Unit\"\n",
    "    df_valid_data = mark_units(df_valid_data)\n",
    "\n",
    "    # Further identify valid information and set priority to 2\n",
    "    df_valid_data = update_priority_marks(df_valid_data)\n",
    "\n",
    "    # Calculate row differences of target information for subsequent matching\n",
    "    df_goal_data,delete_rows_count = calculate_row_diff(df_valid_data)\n",
    "    \n",
    "    # Delete unmatched extra information\n",
    "    df_goal_data = delete_by_row_diff(df_goal_data, delete_rows_count)\n",
    "\n",
    "    # Retrieve matched information\n",
    "    df_matched_goal_data = create_matched_dataframe(df_goal_data)\n",
    "\n",
    "    print(\"✅ Target information extraction completed\")    \n",
    "    return date_str, df_mark_data, df_valid_data, df_goal_data, df_matched_goal_data\n",
    "\n",
    "    \n",
    "# Process 3: Interactive visualization page\n",
    "def process3_display(date, df):\n",
    "    print(\"\\nProcess 3: Creating viewer...\")\n",
    "    receipt = {\n",
    "    'date': date,\n",
    "    'items': df.rename(\n",
    "                columns={'item': 'Item', 'price': 'Price'}).to_dict('records')}\n",
    "    create_interactive_viewer(receipt)\n",
    "    return \"Thank you!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2299fb-673d-4c23-af77-cce35fd1430a",
   "metadata": {},
   "source": [
    "# Entry point ⬇️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "7f3c340c-0026-42c4-bba5-fb8b95ab4aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Processing: X00016469672.jpg\n",
      "======================================================================\n",
      "Process 1: Get data...\n",
      "Step 1: Preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/Users/chiara/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('UVDoc', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/Users/chiara/.paddlex/official_models/UVDoc`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/Users/chiara/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessing done\n",
      "\n",
      "Step 2: OCR Recognition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/Users/chiara/.paddlex/official_models/PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('en_PP-OCRv5_mobile_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/Users/chiara/.paddlex/official_models/en_PP-OCRv5_mobile_rec`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Detected 15 text regions\n",
      "\n",
      "Step 3: Organizing data...\n",
      "Organize OCR data...\n",
      "✅ Data organized\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>confidence</th>\n",
       "      <th>left_top_x</th>\n",
       "      <th>left_top_y</th>\n",
       "      <th>right_top_x</th>\n",
       "      <th>right_top_y</th>\n",
       "      <th>left_bottom_x</th>\n",
       "      <th>left_bottom_y</th>\n",
       "      <th>right_bottom_x</th>\n",
       "      <th>right_bottom_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tan chay yee</td>\n",
       "      <td>0.991900</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>316</td>\n",
       "      <td>0</td>\n",
       "      <td>316</td>\n",
       "      <td>33</td>\n",
       "      <td>97</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOON HUAT MACHINERY ENTERPRISE</td>\n",
       "      <td>0.984482</td>\n",
       "      <td>19</td>\n",
       "      <td>53</td>\n",
       "      <td>431</td>\n",
       "      <td>61</td>\n",
       "      <td>430</td>\n",
       "      <td>88</td>\n",
       "      <td>18</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(JM0352019-K)</td>\n",
       "      <td>0.974050</td>\n",
       "      <td>160</td>\n",
       "      <td>79</td>\n",
       "      <td>294</td>\n",
       "      <td>82</td>\n",
       "      <td>293</td>\n",
       "      <td>110</td>\n",
       "      <td>159</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NO.53 JALAN PUTRA 1.</td>\n",
       "      <td>0.971054</td>\n",
       "      <td>127</td>\n",
       "      <td>107</td>\n",
       "      <td>327</td>\n",
       "      <td>110</td>\n",
       "      <td>326</td>\n",
       "      <td>135</td>\n",
       "      <td>126</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TAMAN SRI PUTRA.</td>\n",
       "      <td>0.994149</td>\n",
       "      <td>142</td>\n",
       "      <td>133</td>\n",
       "      <td>312</td>\n",
       "      <td>135</td>\n",
       "      <td>312</td>\n",
       "      <td>159</td>\n",
       "      <td>142</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>327.00</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>354</td>\n",
       "      <td>1082</td>\n",
       "      <td>413</td>\n",
       "      <td>1082</td>\n",
       "      <td>413</td>\n",
       "      <td>1103</td>\n",
       "      <td>354</td>\n",
       "      <td>1103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>CASH :</td>\n",
       "      <td>0.990495</td>\n",
       "      <td>244</td>\n",
       "      <td>1113</td>\n",
       "      <td>323</td>\n",
       "      <td>1110</td>\n",
       "      <td>324</td>\n",
       "      <td>1135</td>\n",
       "      <td>244</td>\n",
       "      <td>1138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>327.00</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>355</td>\n",
       "      <td>1114</td>\n",
       "      <td>414</td>\n",
       "      <td>1114</td>\n",
       "      <td>414</td>\n",
       "      <td>1134</td>\n",
       "      <td>355</td>\n",
       "      <td>1134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Change :</td>\n",
       "      <td>0.991664</td>\n",
       "      <td>226</td>\n",
       "      <td>1139</td>\n",
       "      <td>322</td>\n",
       "      <td>1135</td>\n",
       "      <td>323</td>\n",
       "      <td>1160</td>\n",
       "      <td>227</td>\n",
       "      <td>1163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.999798</td>\n",
       "      <td>374</td>\n",
       "      <td>1137</td>\n",
       "      <td>415</td>\n",
       "      <td>1137</td>\n",
       "      <td>415</td>\n",
       "      <td>1159</td>\n",
       "      <td>374</td>\n",
       "      <td>1159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              text  confidence  left_top_x  left_top_y  \\\n",
       "0                     tan chay yee    0.991900          97           0   \n",
       "1   SOON HUAT MACHINERY ENTERPRISE    0.984482          19          53   \n",
       "2                    (JM0352019-K)    0.974050         160          79   \n",
       "3             NO.53 JALAN PUTRA 1.    0.971054         127         107   \n",
       "4                 TAMAN SRI PUTRA.    0.994149         142         133   \n",
       "..                             ...         ...         ...         ...   \n",
       "86                          327.00    0.999899         354        1082   \n",
       "87                          CASH :    0.990495         244        1113   \n",
       "88                          327.00    0.999916         355        1114   \n",
       "89                        Change :    0.991664         226        1139   \n",
       "90                            0.00    0.999798         374        1137   \n",
       "\n",
       "    right_top_x  right_top_y  left_bottom_x  left_bottom_y  right_bottom_x  \\\n",
       "0           316            0            316             33              97   \n",
       "1           431           61            430             88              18   \n",
       "2           294           82            293            110             159   \n",
       "3           327          110            326            135             126   \n",
       "4           312          135            312            159             142   \n",
       "..          ...          ...            ...            ...             ...   \n",
       "86          413         1082            413           1103             354   \n",
       "87          323         1110            324           1135             244   \n",
       "88          414         1114            414           1134             355   \n",
       "89          322         1135            323           1160             227   \n",
       "90          415         1137            415           1159             374   \n",
       "\n",
       "    right_bottom_y  \n",
       "0               33  \n",
       "1               80  \n",
       "2              107  \n",
       "3              131  \n",
       "4              157  \n",
       "..             ...  \n",
       "86            1103  \n",
       "87            1138  \n",
       "88            1134  \n",
       "89            1163  \n",
       "90            1159  \n",
       "\n",
       "[91 rows x 10 columns]"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process 1: Get data – Image preprocessing and OCR recognition\n",
    "\n",
    "# Input image path\n",
    "# image_path = 'X00016469612.jpg'\n",
    "image_path = 'X00016469672.jpg'\n",
    "# image_path = 'X00016469622.jpg'\n",
    "\n",
    "# Get raw OCR data and save to DataFrame\n",
    "df_ocr_result = process1_getdata(image_path)\n",
    "\n",
    "# Print raw data\n",
    "df_ocr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "f57fe9a9-3aa8-4318-9cd9-1e0a2f9133ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Process 2: Extracting information...\n",
      "Step 4: Add mark column...\n",
      "\n",
      "Step 5: Add row number column...\n",
      "\n",
      "Step 6: Add priority column...\n",
      "\n",
      "Step 7: Add column number column...\n",
      "\n",
      "Step 8: Mark units...\n",
      "\n",
      "Step 9: Update priority marks...\n",
      "\n",
      "Step 10: Calculate row differences...\n",
      "\n",
      "Step 11: Delete rows based on row_diff...\n",
      "\n",
      "Step 12: Create matched DataFrame...\n",
      "Final matched DataFrame:\n",
      "Total matched pairs: 8\n",
      "======================================================================\n",
      "\n",
      "✅ Target information extraction completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REPAIR ENGINE POWER SPRAYER (1UNIT)</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GIANT 606 OVERFLOW ASSY</td>\n",
       "      <td>160.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENGINE OIL</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GREASE FOR TOOLS 40ML (AKODA)</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EY20 PLUG CHAMPION</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>STARTER TALI</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EY20 STARTER HANDLE</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HD40 1L COTIN</td>\n",
       "      <td>36.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  item   price\n",
       "0  REPAIR ENGINE POWER SPRAYER (1UNIT)   80.00\n",
       "1              GIANT 606 OVERFLOW ASSY  160.00\n",
       "2                           ENGINE OIL   17.00\n",
       "3        GREASE FOR TOOLS 40ML (AKODA)   10.00\n",
       "4                   EY20 PLUG CHAMPION    6.00\n",
       "5                         STARTER TALI    8.00\n",
       "6                  EY20 STARTER HANDLE   10.00\n",
       "7                        HD40 1L COTIN   36.00"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process 2: Extracting information\n",
    "'''\n",
    "date: extracted date\n",
    "df_mark_data: data with category labels\n",
    "df_valid_data: first-stage filtered data (priority = 1)\n",
    "df_goal_data: second-stage filtered data (priority = 2) with unmatched rows removed\n",
    "df_matched_goal_data: final data after information matching \n",
    "'''\n",
    "# Get data from different stages\n",
    "date, df_mark_data, df_valid_data, df_goal_data, df_matched_goal_data = process2_get_main_information(df_ocr_result)\n",
    "\n",
    "# Print final data\n",
    "df_matched_goal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "82565ec9-e407-4f08-89e6-1f5e9e5afc3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Process 3: Creating viewer...\n",
      "\n",
      "============================\n",
      "RECEIPT VIEWER\n",
      "============================\n",
      "Date       : 01/11/2019\n",
      "Receipt ID : 1\n",
      "Items      : 8\n",
      "============================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511fc58e708a444591e6c32272ffda0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58dbffb9568c4e99ac298587ef074a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32853a64bbce426fbf8b44d5c5291184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=1, description='Row:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "449ae169049b4bea923b3f995250038c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Item:', placeholder='Item name (max 30 letters)')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47b7957e2c94c89b1c7b9e7445d7e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Price:', placeholder='e.g. 12.50')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2221c212b6a146f6a74544ac2e1d1fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='success', description='Add', style=ButtonStyle()), Button(button_style='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c8b4cd7b994fe380490b20ed5215c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Instructions:\n",
      "1) Add: both Item and Price required.\n",
      "2) Update: leave a field empty to keep original.\n",
      "3) Price format: digits or decimal, e.g. 12 or 12.50\n",
      "4) Item: non-empty and max 30 letters.\n",
      "========================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Thank you!'"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process 3: Interactive visualization page\n",
    "\n",
    "process3_display(date, df_matched_goal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f738125-732a-4607-ab0a-9fdc0b3fc041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
